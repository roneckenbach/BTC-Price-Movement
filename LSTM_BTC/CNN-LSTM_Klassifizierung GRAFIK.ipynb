{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Bibliotheken\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import ta\n",
    "\n",
    "#.\\venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/WWI2021/Semester 6/Machine Learning Project/mlruns/4', creation_time=1717926362013, experiment_id='4', last_update_time=1717926362013, lifecycle_stage='active', name='Bitcoin Price Movement Prediction CNN LSTM Learning Rate', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 127.0.0.1 --port 8080\n",
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\WWI2021\\Semester 6\\Machine Learning Project\\LSTM_BTC\\data\\BTC-USD.csv\")\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RSI'] = ta.momentum.RSIIndicator(data['Close']).rsi()\n",
    "data['EMA20'] = ta.trend.EMAIndicator(data['Close'], window=20).ema_indicator()\n",
    "data['EMA100'] = ta.trend.EMAIndicator(data['Close'], window=100).ema_indicator()\n",
    "data['EMA150'] = ta.trend.EMAIndicator(data['Close'], window=150).ema_indicator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Moving Average (SMA)\n",
    "data['SMA50'] = ta.trend.SMAIndicator(close=data['Close'], window=50).sma_indicator()\n",
    "# Momentum Indicator\n",
    "data['Momentum'] = ta.momentum.ROCIndicator(close=data['Close'], window=10).roc()\n",
    "# Rate of Change (ROC)\n",
    "data['ROC'] = ta.momentum.ROCIndicator(close=data['Close'], window=12).roc()\n",
    "# Bollinger Bands\n",
    "bollinger = ta.volatility.BollingerBands(close=data['Close'], window=20, window_dev=2)\n",
    "data['Bollinger_Middle'] = bollinger.bollinger_mavg()\n",
    "data['Bollinger_Upper'] = bollinger.bollinger_hband()\n",
    "data['Bollinger_Lower'] = bollinger.bollinger_lband()\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "macd = ta.trend.MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "data['MACD'] = macd.macd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Date','High', 'Low', 'Adj Close', 'Volume','Open', 'EMA100', 'EMA150', 'SMA50', 'Momentum', 'ROC', 'Bollinger_Upper', 'Bollinger_Lower'], axis=1, inplace=True)\n",
    "data['Previous_Close'] = data['Close'].shift(1)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequenzlänge Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:39:01 INFO mlflow.tracking.fluent: Experiment with name 'Bitcoin Price Movement Prediction CNN LSTM Sequence Length' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5293 - loss: 0.6947 - val_accuracy: 0.4864 - val_loss: 0.6996\n",
      "Epoch 2/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 0.6873 - val_accuracy: 0.4864 - val_loss: 0.6953\n",
      "Epoch 3/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5455 - loss: 0.6893 - val_accuracy: 0.4864 - val_loss: 0.6958\n",
      "Epoch 4/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5167 - loss: 0.6925 - val_accuracy: 0.4864 - val_loss: 0.7047\n",
      "Epoch 5/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5492 - loss: 0.6881 - val_accuracy: 0.4864 - val_loss: 0.6974\n",
      "Epoch 6/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5536 - loss: 0.6869 - val_accuracy: 0.4864 - val_loss: 0.6946\n",
      "Epoch 7/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5528 - loss: 0.6877 - val_accuracy: 0.4864 - val_loss: 0.6961\n",
      "Epoch 8/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5405 - loss: 0.6898 - val_accuracy: 0.4864 - val_loss: 0.6973\n",
      "Epoch 9/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5441 - loss: 0.6885 - val_accuracy: 0.4864 - val_loss: 0.6977\n",
      "Epoch 10/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 0.6852 - val_accuracy: 0.4864 - val_loss: 0.6963\n",
      "Epoch 11/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5399 - loss: 0.6881 - val_accuracy: 0.4864 - val_loss: 0.6965\n",
      "Epoch 12/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5519 - loss: 0.6863 - val_accuracy: 0.4864 - val_loss: 0.6963\n",
      "Epoch 13/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5426 - loss: 0.6891 - val_accuracy: 0.4864 - val_loss: 0.6969\n",
      "Epoch 14/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5551 - loss: 0.6843 - val_accuracy: 0.4864 - val_loss: 0.6952\n",
      "Epoch 15/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5400 - loss: 0.6887 - val_accuracy: 0.4864 - val_loss: 0.6961\n",
      "Epoch 16/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5490 - loss: 0.6870 - val_accuracy: 0.4864 - val_loss: 0.6962\n",
      "Epoch 17/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5522 - loss: 0.6860 - val_accuracy: 0.4864 - val_loss: 0.6947\n",
      "Epoch 18/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5529 - loss: 0.6854 - val_accuracy: 0.4864 - val_loss: 0.6938\n",
      "Epoch 19/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5250 - loss: 0.6882 - val_accuracy: 0.4864 - val_loss: 0.6960\n",
      "Epoch 20/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5530 - loss: 0.6848 - val_accuracy: 0.4864 - val_loss: 0.6953\n",
      "Epoch 21/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5409 - loss: 0.6900 - val_accuracy: 0.4864 - val_loss: 0.7006\n",
      "Epoch 22/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5453 - loss: 0.6878 - val_accuracy: 0.4864 - val_loss: 0.6974\n",
      "Epoch 23/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5521 - loss: 0.6824 - val_accuracy: 0.4864 - val_loss: 0.6947\n",
      "Epoch 24/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5479 - loss: 0.6879 - val_accuracy: 0.4864 - val_loss: 0.6950\n",
      "Epoch 25/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5519 - loss: 0.6864 - val_accuracy: 0.4864 - val_loss: 0.6942\n",
      "Epoch 26/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5544 - loss: 0.6884 - val_accuracy: 0.4864 - val_loss: 0.6995\n",
      "Epoch 27/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 0.6891 - val_accuracy: 0.4864 - val_loss: 0.6959\n",
      "Epoch 28/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5411 - loss: 0.6878 - val_accuracy: 0.4864 - val_loss: 0.6948\n",
      "Epoch 29/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5517 - loss: 0.6889 - val_accuracy: 0.4864 - val_loss: 0.6950\n",
      "Epoch 30/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5486 - loss: 0.6855 - val_accuracy: 0.4864 - val_loss: 0.6953\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5010 - loss: 0.6939 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:39:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6925584077835083\n",
      "Test Accuracy: 0.5171428322792053\n",
      "Epoch 1/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5206 - loss: 0.6924 - val_accuracy: 0.4871 - val_loss: 0.6962\n",
      "Epoch 2/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5386 - loss: 0.6906 - val_accuracy: 0.4871 - val_loss: 0.7032\n",
      "Epoch 3/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5310 - loss: 0.6933 - val_accuracy: 0.4871 - val_loss: 0.7003\n",
      "Epoch 4/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5395 - loss: 0.6897 - val_accuracy: 0.4871 - val_loss: 0.6992\n",
      "Epoch 5/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5234 - loss: 0.6926 - val_accuracy: 0.4871 - val_loss: 0.6997\n",
      "Epoch 6/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5456 - loss: 0.6891 - val_accuracy: 0.4871 - val_loss: 0.6992\n",
      "Epoch 7/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5520 - loss: 0.6877 - val_accuracy: 0.4871 - val_loss: 0.6974\n",
      "Epoch 8/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5372 - loss: 0.6888 - val_accuracy: 0.4871 - val_loss: 0.6965\n",
      "Epoch 9/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 0.6875 - val_accuracy: 0.4871 - val_loss: 0.6996\n",
      "Epoch 10/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5648 - loss: 0.6862 - val_accuracy: 0.4871 - val_loss: 0.6973\n",
      "Epoch 11/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5644 - loss: 0.6862 - val_accuracy: 0.4871 - val_loss: 0.6978\n",
      "Epoch 12/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5436 - loss: 0.6898 - val_accuracy: 0.4871 - val_loss: 0.6988\n",
      "Epoch 13/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5574 - loss: 0.6872 - val_accuracy: 0.4871 - val_loss: 0.7000\n",
      "Epoch 14/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5510 - loss: 0.6881 - val_accuracy: 0.4871 - val_loss: 0.6993\n",
      "Epoch 15/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5392 - loss: 0.6903 - val_accuracy: 0.4871 - val_loss: 0.7002\n",
      "Epoch 16/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5532 - loss: 0.6877 - val_accuracy: 0.4871 - val_loss: 0.6995\n",
      "Epoch 17/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5408 - loss: 0.6899 - val_accuracy: 0.4871 - val_loss: 0.7010\n",
      "Epoch 18/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5408 - loss: 0.6902 - val_accuracy: 0.4871 - val_loss: 0.7004\n",
      "Epoch 19/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5382 - loss: 0.6906 - val_accuracy: 0.4871 - val_loss: 0.7000\n",
      "Epoch 20/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5540 - loss: 0.6874 - val_accuracy: 0.4871 - val_loss: 0.7004\n",
      "Epoch 21/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5525 - loss: 0.6878 - val_accuracy: 0.4871 - val_loss: 0.6989\n",
      "Epoch 22/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5398 - loss: 0.6902 - val_accuracy: 0.4871 - val_loss: 0.7007\n",
      "Epoch 23/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 0.6877 - val_accuracy: 0.4871 - val_loss: 0.6994\n",
      "Epoch 24/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5500 - loss: 0.6885 - val_accuracy: 0.4871 - val_loss: 0.7000\n",
      "Epoch 25/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5507 - loss: 0.6882 - val_accuracy: 0.4871 - val_loss: 0.7006\n",
      "Epoch 26/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5260 - loss: 0.6930 - val_accuracy: 0.4871 - val_loss: 0.7014\n",
      "Epoch 27/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5471 - loss: 0.6889 - val_accuracy: 0.4871 - val_loss: 0.6998\n",
      "Epoch 28/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5552 - loss: 0.6874 - val_accuracy: 0.4871 - val_loss: 0.6997\n",
      "Epoch 29/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5370 - loss: 0.6907 - val_accuracy: 0.4871 - val_loss: 0.7005\n",
      "Epoch 30/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5629 - loss: 0.6862 - val_accuracy: 0.4871 - val_loss: 0.6990\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 0.6971 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:39:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6941014528274536\n",
      "Test Accuracy: 0.515759289264679\n",
      "Epoch 1/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: 0.6909 - val_accuracy: 0.4863 - val_loss: 0.6961\n",
      "Epoch 2/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5251 - loss: 0.6940 - val_accuracy: 0.4863 - val_loss: 0.7004\n",
      "Epoch 3/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5465 - loss: 0.6894 - val_accuracy: 0.4863 - val_loss: 0.6997\n",
      "Epoch 4/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5307 - loss: 0.6921 - val_accuracy: 0.4863 - val_loss: 0.7000\n",
      "Epoch 5/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5507 - loss: 0.6882 - val_accuracy: 0.4863 - val_loss: 0.6997\n",
      "Epoch 6/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5646 - loss: 0.6853 - val_accuracy: 0.4863 - val_loss: 0.6984\n",
      "Epoch 7/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5368 - loss: 0.6905 - val_accuracy: 0.4863 - val_loss: 0.7008\n",
      "Epoch 8/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5548 - loss: 0.6875 - val_accuracy: 0.4863 - val_loss: 0.6990\n",
      "Epoch 9/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5452 - loss: 0.6890 - val_accuracy: 0.4863 - val_loss: 0.7004\n",
      "Epoch 10/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5387 - loss: 0.6909 - val_accuracy: 0.4863 - val_loss: 0.6993\n",
      "Epoch 11/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5484 - loss: 0.6889 - val_accuracy: 0.4863 - val_loss: 0.6984\n",
      "Epoch 12/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5417 - loss: 0.6902 - val_accuracy: 0.4863 - val_loss: 0.6988\n",
      "Epoch 13/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5489 - loss: 0.6882 - val_accuracy: 0.4863 - val_loss: 0.6988\n",
      "Epoch 14/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5336 - loss: 0.6910 - val_accuracy: 0.4863 - val_loss: 0.7014\n",
      "Epoch 15/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5543 - loss: 0.6877 - val_accuracy: 0.4863 - val_loss: 0.7010\n",
      "Epoch 16/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5528 - loss: 0.6878 - val_accuracy: 0.4863 - val_loss: 0.6992\n",
      "Epoch 17/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5171 - loss: 0.6941 - val_accuracy: 0.4863 - val_loss: 0.7016\n",
      "Epoch 18/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5404 - loss: 0.6904 - val_accuracy: 0.4863 - val_loss: 0.7016\n",
      "Epoch 19/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6914 - val_accuracy: 0.4863 - val_loss: 0.7005\n",
      "Epoch 20/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5446 - loss: 0.6896 - val_accuracy: 0.4863 - val_loss: 0.7017\n",
      "Epoch 21/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5506 - loss: 0.6886 - val_accuracy: 0.4863 - val_loss: 0.7000\n",
      "Epoch 22/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5425 - loss: 0.6898 - val_accuracy: 0.4863 - val_loss: 0.7013\n",
      "Epoch 23/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5435 - loss: 0.6896 - val_accuracy: 0.4863 - val_loss: 0.6988\n",
      "Epoch 24/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5284 - loss: 0.6921 - val_accuracy: 0.4863 - val_loss: 0.7004\n",
      "Epoch 25/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5441 - loss: 0.6895 - val_accuracy: 0.4863 - val_loss: 0.7018\n",
      "Epoch 26/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5431 - loss: 0.6897 - val_accuracy: 0.4863 - val_loss: 0.7006\n",
      "Epoch 27/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5403 - loss: 0.6902 - val_accuracy: 0.4863 - val_loss: 0.7005\n",
      "Epoch 28/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5471 - loss: 0.6888 - val_accuracy: 0.4863 - val_loss: 0.7009\n",
      "Epoch 29/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5598 - loss: 0.6863 - val_accuracy: 0.4863 - val_loss: 0.6996\n",
      "Epoch 30/30\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 0.6889 - val_accuracy: 0.4863 - val_loss: 0.6987\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4979 - loss: 0.6968 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:39:46 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6938968300819397\n",
      "Test Accuracy: 0.515759289264679\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5450 - loss: 0.6922 - val_accuracy: 0.4885 - val_loss: 0.7065\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5408 - loss: 0.6900 - val_accuracy: 0.4885 - val_loss: 0.6997\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5389 - loss: 0.6907 - val_accuracy: 0.4885 - val_loss: 0.6980\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5326 - loss: 0.6912 - val_accuracy: 0.4885 - val_loss: 0.6973\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.6904 - val_accuracy: 0.4885 - val_loss: 0.6997\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 0.6891 - val_accuracy: 0.4885 - val_loss: 0.6974\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5534 - loss: 0.6857 - val_accuracy: 0.4885 - val_loss: 0.6954\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5465 - loss: 0.6892 - val_accuracy: 0.4885 - val_loss: 0.7000\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5581 - loss: 0.6867 - val_accuracy: 0.4885 - val_loss: 0.6983\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5447 - loss: 0.6893 - val_accuracy: 0.4885 - val_loss: 0.6992\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5618 - loss: 0.6862 - val_accuracy: 0.4885 - val_loss: 0.6968\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5405 - loss: 0.6900 - val_accuracy: 0.4885 - val_loss: 0.6999\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5444 - loss: 0.6895 - val_accuracy: 0.4885 - val_loss: 0.6997\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5533 - loss: 0.6873 - val_accuracy: 0.4885 - val_loss: 0.6986\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5510 - loss: 0.6883 - val_accuracy: 0.4885 - val_loss: 0.6990\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5465 - loss: 0.6890 - val_accuracy: 0.4885 - val_loss: 0.6990\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 0.6895 - val_accuracy: 0.4885 - val_loss: 0.6983\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 0.6884 - val_accuracy: 0.4885 - val_loss: 0.7005\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5400 - loss: 0.6901 - val_accuracy: 0.4885 - val_loss: 0.7014\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5504 - loss: 0.6886 - val_accuracy: 0.4885 - val_loss: 0.6985\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5349 - loss: 0.6908 - val_accuracy: 0.4885 - val_loss: 0.7004\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5344 - loss: 0.6914 - val_accuracy: 0.4885 - val_loss: 0.7009\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5419 - loss: 0.6900 - val_accuracy: 0.4885 - val_loss: 0.7006\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5491 - loss: 0.6887 - val_accuracy: 0.4885 - val_loss: 0.6982\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5521 - loss: 0.6881 - val_accuracy: 0.4885 - val_loss: 0.6992\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5557 - loss: 0.6873 - val_accuracy: 0.4885 - val_loss: 0.6982\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5328 - loss: 0.6912 - val_accuracy: 0.4885 - val_loss: 0.7012\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5444 - loss: 0.6895 - val_accuracy: 0.4885 - val_loss: 0.6998\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5512 - loss: 0.6881 - val_accuracy: 0.4885 - val_loss: 0.6991\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5541 - loss: 0.6877 - val_accuracy: 0.4885 - val_loss: 0.6986\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:40:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6942546367645264\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5425 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5472 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7021\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5421 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6978\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5533 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5473 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5596 - loss: 0.6860 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5416 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7006\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5522 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5377 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5426 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5545 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5647 - loss: 0.6856 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5351 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5560 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6860 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5349 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5503 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5465 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5396 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5288 - loss: 0.6924 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5654 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5505 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6970 \n",
      "Test Loss: 0.6940649151802063\n",
      "Test Accuracy: 0.5143678188323975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:40:28 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5290 - loss: 0.6915 - val_accuracy: 0.4870 - val_loss: 0.7001\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5535 - loss: 0.6883 - val_accuracy: 0.4870 - val_loss: 0.6995\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5560 - loss: 0.6877 - val_accuracy: 0.4870 - val_loss: 0.6983\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5442 - loss: 0.6896 - val_accuracy: 0.4870 - val_loss: 0.7016\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5492 - loss: 0.6883 - val_accuracy: 0.4870 - val_loss: 0.6992\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5591 - loss: 0.6867 - val_accuracy: 0.4870 - val_loss: 0.6983\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 0.6882 - val_accuracy: 0.4870 - val_loss: 0.6983\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5415 - loss: 0.6899 - val_accuracy: 0.4870 - val_loss: 0.7004\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5395 - loss: 0.6905 - val_accuracy: 0.4870 - val_loss: 0.7019\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 0.6926 - val_accuracy: 0.4870 - val_loss: 0.7005\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5412 - loss: 0.6900 - val_accuracy: 0.4870 - val_loss: 0.7005\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5443 - loss: 0.6892 - val_accuracy: 0.4870 - val_loss: 0.7010\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5594 - loss: 0.6868 - val_accuracy: 0.4870 - val_loss: 0.6979\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5534 - loss: 0.6881 - val_accuracy: 0.4870 - val_loss: 0.6999\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5306 - loss: 0.6918 - val_accuracy: 0.4870 - val_loss: 0.7005\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5193 - loss: 0.6943 - val_accuracy: 0.4870 - val_loss: 0.7016\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5507 - loss: 0.6884 - val_accuracy: 0.4870 - val_loss: 0.7002\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5461 - loss: 0.6890 - val_accuracy: 0.4870 - val_loss: 0.7000\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5501 - loss: 0.6883 - val_accuracy: 0.4870 - val_loss: 0.6997\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5372 - loss: 0.6906 - val_accuracy: 0.4870 - val_loss: 0.7009\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5407 - loss: 0.6901 - val_accuracy: 0.4870 - val_loss: 0.7003\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5627 - loss: 0.6858 - val_accuracy: 0.4870 - val_loss: 0.6985\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5378 - loss: 0.6905 - val_accuracy: 0.4870 - val_loss: 0.7012\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5426 - loss: 0.6897 - val_accuracy: 0.4870 - val_loss: 0.6993\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5286 - loss: 0.6921 - val_accuracy: 0.4870 - val_loss: 0.7012\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5411 - loss: 0.6902 - val_accuracy: 0.4870 - val_loss: 0.6996\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5516 - loss: 0.6879 - val_accuracy: 0.4870 - val_loss: 0.7002\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5357 - loss: 0.6915 - val_accuracy: 0.4870 - val_loss: 0.7002\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5570 - loss: 0.6870 - val_accuracy: 0.4870 - val_loss: 0.6985\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 0.6891 - val_accuracy: 0.4870 - val_loss: 0.7007\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4891 - loss: 0.7003 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:40:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6955080032348633\n",
      "Test Accuracy: 0.5129683017730713\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5353 - loss: 0.7503 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5573 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6959\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5503 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5654 - loss: 0.6851 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5420 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5362 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.7018\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5493 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5444 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5548 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5505 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5290 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5423 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5564 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5552 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5296 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5482 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5474 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5482 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5383 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5598 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6978\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5363 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5482 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5373 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5561 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6957\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5447 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5544 - loss: 0.6855 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5526 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5654 - loss: 0.6856 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5320 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5419 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4891 - loss: 0.6947 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:41:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6927930116653442\n",
      "Test Accuracy: 0.5129683017730713\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5029 - loss: 0.6960 - val_accuracy: 0.4884 - val_loss: 0.7039\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5407 - loss: 0.6925 - val_accuracy: 0.4884 - val_loss: 0.6985\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5456 - loss: 0.6891 - val_accuracy: 0.4884 - val_loss: 0.6972\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5344 - loss: 0.6909 - val_accuracy: 0.4884 - val_loss: 0.7001\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5362 - loss: 0.6914 - val_accuracy: 0.4884 - val_loss: 0.7000\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5601 - loss: 0.6863 - val_accuracy: 0.4884 - val_loss: 0.6969\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5490 - loss: 0.6890 - val_accuracy: 0.4884 - val_loss: 0.6984\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5476 - loss: 0.6881 - val_accuracy: 0.4884 - val_loss: 0.6977\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5510 - loss: 0.6881 - val_accuracy: 0.4884 - val_loss: 0.6977\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5540 - loss: 0.6876 - val_accuracy: 0.4884 - val_loss: 0.6973\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5419 - loss: 0.6897 - val_accuracy: 0.4884 - val_loss: 0.6973\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5440 - loss: 0.6884 - val_accuracy: 0.4884 - val_loss: 0.6965\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5549 - loss: 0.6887 - val_accuracy: 0.4884 - val_loss: 0.6979\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5482 - loss: 0.6889 - val_accuracy: 0.4884 - val_loss: 0.6985\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5594 - loss: 0.6869 - val_accuracy: 0.4884 - val_loss: 0.6987\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5510 - loss: 0.6882 - val_accuracy: 0.4884 - val_loss: 0.6985\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5597 - loss: 0.6866 - val_accuracy: 0.4884 - val_loss: 0.6983\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5522 - loss: 0.6881 - val_accuracy: 0.4884 - val_loss: 0.6990\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5312 - loss: 0.6911 - val_accuracy: 0.4884 - val_loss: 0.6983\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5531 - loss: 0.6869 - val_accuracy: 0.4884 - val_loss: 0.6964\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.4884 - val_loss: 0.6998\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5485 - loss: 0.6877 - val_accuracy: 0.4884 - val_loss: 0.7001\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5319 - loss: 0.6918 - val_accuracy: 0.4884 - val_loss: 0.7027\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5347 - loss: 0.6914 - val_accuracy: 0.4884 - val_loss: 0.7017\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5426 - loss: 0.6899 - val_accuracy: 0.4884 - val_loss: 0.6981\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5475 - loss: 0.6877 - val_accuracy: 0.4884 - val_loss: 0.6972\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5473 - loss: 0.6883 - val_accuracy: 0.4884 - val_loss: 0.6947\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5409 - loss: 0.6879 - val_accuracy: 0.4884 - val_loss: 0.6969\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5366 - loss: 0.6909 - val_accuracy: 0.4884 - val_loss: 0.6990\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5641 - loss: 0.6840 - val_accuracy: 0.4884 - val_loss: 0.6967\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4850 - loss: 0.6972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:41:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6937366127967834\n",
      "Test Accuracy: 0.5115606784820557\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5641 - loss: 0.6909 - val_accuracy: 0.4891 - val_loss: 0.6966\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5406 - loss: 0.6896 - val_accuracy: 0.4891 - val_loss: 0.6985\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5494 - loss: 0.6884 - val_accuracy: 0.4891 - val_loss: 0.6972\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5460 - loss: 0.6883 - val_accuracy: 0.4891 - val_loss: 0.6974\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5371 - loss: 0.6902 - val_accuracy: 0.4891 - val_loss: 0.6963\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5372 - loss: 0.6895 - val_accuracy: 0.4891 - val_loss: 0.6952\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5450 - loss: 0.6878 - val_accuracy: 0.4891 - val_loss: 0.6968\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5374 - loss: 0.6899 - val_accuracy: 0.4891 - val_loss: 0.6954\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5446 - loss: 0.6886 - val_accuracy: 0.4891 - val_loss: 0.6955\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5467 - loss: 0.6850 - val_accuracy: 0.4891 - val_loss: 0.6948\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5502 - loss: 0.6883 - val_accuracy: 0.4891 - val_loss: 0.6966\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5412 - loss: 0.6880 - val_accuracy: 0.4891 - val_loss: 0.6961\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5465 - loss: 0.6878 - val_accuracy: 0.4891 - val_loss: 0.6948\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5391 - loss: 0.6871 - val_accuracy: 0.4891 - val_loss: 0.6986\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5417 - loss: 0.6873 - val_accuracy: 0.4891 - val_loss: 0.6953\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5492 - loss: 0.6874 - val_accuracy: 0.4891 - val_loss: 0.6951\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5587 - loss: 0.6838 - val_accuracy: 0.4891 - val_loss: 0.6941\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5570 - loss: 0.6839 - val_accuracy: 0.4891 - val_loss: 0.6940\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5289 - loss: 0.6904 - val_accuracy: 0.4891 - val_loss: 0.6945\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5444 - loss: 0.6864 - val_accuracy: 0.4891 - val_loss: 0.6970\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5593 - loss: 0.6825 - val_accuracy: 0.4891 - val_loss: 0.6939\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5272 - loss: 0.6898 - val_accuracy: 0.4891 - val_loss: 0.6948\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5434 - loss: 0.6863 - val_accuracy: 0.4891 - val_loss: 0.6933\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5552 - loss: 0.6879 - val_accuracy: 0.4891 - val_loss: 0.6946\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5523 - loss: 0.6847 - val_accuracy: 0.4891 - val_loss: 0.6948\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5583 - loss: 0.6881 - val_accuracy: 0.4891 - val_loss: 0.6970\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5407 - loss: 0.6864 - val_accuracy: 0.4891 - val_loss: 0.6993\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5441 - loss: 0.6828 - val_accuracy: 0.4891 - val_loss: 0.6957\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5517 - loss: 0.6854 - val_accuracy: 0.4891 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5444 - loss: 0.6844 - val_accuracy: 0.4891 - val_loss: 0.6947\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4850 - loss: 0.6948 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:42:18 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.693183958530426\n",
      "Test Accuracy: 0.5115606784820557\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5016 - loss: 0.8365 - val_accuracy: 0.4884 - val_loss: 0.6955\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5655 - loss: 0.6871 - val_accuracy: 0.4884 - val_loss: 0.6952\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.4884 - val_loss: 0.6975\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.6918 - val_accuracy: 0.4884 - val_loss: 0.6979\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5406 - loss: 0.6899 - val_accuracy: 0.4884 - val_loss: 0.6971\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5538 - loss: 0.6870 - val_accuracy: 0.4884 - val_loss: 0.6962\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5532 - loss: 0.6855 - val_accuracy: 0.4884 - val_loss: 0.6958\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5499 - loss: 0.6877 - val_accuracy: 0.4884 - val_loss: 0.6973\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5441 - loss: 0.6886 - val_accuracy: 0.4884 - val_loss: 0.6971\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5717 - loss: 0.6829 - val_accuracy: 0.4884 - val_loss: 0.6951\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5405 - loss: 0.6880 - val_accuracy: 0.4884 - val_loss: 0.6951\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5398 - loss: 0.6894 - val_accuracy: 0.4884 - val_loss: 0.6947\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5513 - loss: 0.6872 - val_accuracy: 0.4884 - val_loss: 0.6988\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5495 - loss: 0.6915 - val_accuracy: 0.4884 - val_loss: 0.6975\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5437 - loss: 0.6896 - val_accuracy: 0.4884 - val_loss: 0.6995\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5476 - loss: 0.6887 - val_accuracy: 0.4884 - val_loss: 0.6989\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5550 - loss: 0.6875 - val_accuracy: 0.4884 - val_loss: 0.6985\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5617 - loss: 0.6863 - val_accuracy: 0.4884 - val_loss: 0.6984\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5550 - loss: 0.6878 - val_accuracy: 0.4884 - val_loss: 0.6979\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5465 - loss: 0.6889 - val_accuracy: 0.4884 - val_loss: 0.7000\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5565 - loss: 0.6871 - val_accuracy: 0.4884 - val_loss: 0.6977\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5453 - loss: 0.6892 - val_accuracy: 0.4884 - val_loss: 0.7001\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5515 - loss: 0.6880 - val_accuracy: 0.4884 - val_loss: 0.6994\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5417 - loss: 0.6900 - val_accuracy: 0.4884 - val_loss: 0.6978\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5329 - loss: 0.6915 - val_accuracy: 0.4884 - val_loss: 0.7016\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5482 - loss: 0.6887 - val_accuracy: 0.4884 - val_loss: 0.6990\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5472 - loss: 0.6888 - val_accuracy: 0.4884 - val_loss: 0.6996\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5571 - loss: 0.6871 - val_accuracy: 0.4884 - val_loss: 0.6982\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5519 - loss: 0.6881 - val_accuracy: 0.4884 - val_loss: 0.6992\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5510 - loss: 0.6882 - val_accuracy: 0.4884 - val_loss: 0.6989\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4914 - loss: 0.6984 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:42:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.694616973400116\n",
      "Test Accuracy: 0.5130434632301331\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5429 - loss: 0.6914 - val_accuracy: 0.4876 - val_loss: 0.7006\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5605 - loss: 0.6868 - val_accuracy: 0.4876 - val_loss: 0.6973\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5365 - loss: 0.6906 - val_accuracy: 0.4876 - val_loss: 0.6998\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5337 - loss: 0.6912 - val_accuracy: 0.4876 - val_loss: 0.7007\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5304 - loss: 0.6920 - val_accuracy: 0.4876 - val_loss: 0.7033\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5458 - loss: 0.6893 - val_accuracy: 0.4876 - val_loss: 0.6991\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5403 - loss: 0.6905 - val_accuracy: 0.4876 - val_loss: 0.7006\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5323 - loss: 0.7091 - val_accuracy: 0.4876 - val_loss: 0.7017\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5432 - loss: 0.6900 - val_accuracy: 0.4876 - val_loss: 0.6992\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5419 - loss: 0.6898 - val_accuracy: 0.4876 - val_loss: 0.6997\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5516 - loss: 0.6879 - val_accuracy: 0.4876 - val_loss: 0.6985\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5301 - loss: 0.6917 - val_accuracy: 0.4876 - val_loss: 0.7027\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5247 - loss: 0.6940 - val_accuracy: 0.4876 - val_loss: 0.7033\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5306 - loss: 0.6930 - val_accuracy: 0.4876 - val_loss: 0.7005\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5652 - loss: 0.6849 - val_accuracy: 0.4876 - val_loss: 0.6981\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5425 - loss: 0.6897 - val_accuracy: 0.4876 - val_loss: 0.6989\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5476 - loss: 0.6885 - val_accuracy: 0.4876 - val_loss: 0.6975\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5348 - loss: 0.6925 - val_accuracy: 0.4876 - val_loss: 0.6998\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5552 - loss: 0.6872 - val_accuracy: 0.4876 - val_loss: 0.6983\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.6869 - val_accuracy: 0.4876 - val_loss: 0.6991\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5433 - loss: 0.6895 - val_accuracy: 0.4876 - val_loss: 0.6987\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5267 - loss: 0.6915 - val_accuracy: 0.4876 - val_loss: 0.6992\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5432 - loss: 0.6895 - val_accuracy: 0.4876 - val_loss: 0.7007\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5616 - loss: 0.6848 - val_accuracy: 0.4876 - val_loss: 0.6968\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5376 - loss: 0.6894 - val_accuracy: 0.4876 - val_loss: 0.6967\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5636 - loss: 0.6823 - val_accuracy: 0.4876 - val_loss: 0.6935\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5470 - loss: 0.6832 - val_accuracy: 0.4876 - val_loss: 0.6940\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5565 - loss: 0.6879 - val_accuracy: 0.4876 - val_loss: 0.6950\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5283 - loss: 0.6917 - val_accuracy: 0.4876 - val_loss: 0.6977\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5547 - loss: 0.6868 - val_accuracy: 0.4876 - val_loss: 0.6948\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4914 - loss: 0.6946 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:43:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6928858160972595\n",
      "Test Accuracy: 0.5130434632301331\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Zielvariablen für die Vorhersage erstellen\n",
    "data['Target'] = (data['Close'] <= data['Previous_Close']).astype(int)\n",
    "\n",
    "data_clean = data\n",
    "data_clean.dropna(inplace=True)\n",
    "data_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Auswahl und Skalierung der relevanten Features\n",
    "selected_features = ['Close', 'RSI', 'EMA20', 'Bollinger_Middle', 'MACD', 'Previous_Close']\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = sc.fit_transform(data[selected_features])\n",
    "\n",
    "def create_sequences(features, target, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequence = features[i:i + seq_length]\n",
    "        label = target[i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Hyperparameter-Definition\n",
    "SEQ_LENGTHS = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]  # Verschiedene Sequenzlängen\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Sequence Length\")\n",
    "\n",
    "for SEQ_LENGTH in SEQ_LENGTHS:\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seq_length\": SEQ_LENGTH\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Daten vorbereiten basierend auf der aktuellen seq_length\n",
    "        X, y = create_sequences(scaled_features, data['Target'].values, SEQ_LENGTH)\n",
    "\n",
    "        # Datenaufteilung: 70% Training, 20% Validierung, 10% Test\n",
    "        train_size = int(0.7 * len(X))\n",
    "        val_size = int(0.2 * len(X))\n",
    "        test_size = len(X) - train_size - val_size\n",
    "\n",
    "        X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "        y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "        # Umformung der Daten für CNN-LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "        optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "        # Modellarchitektur definieren\n",
    "        model = Sequential()\n",
    "        # Hinzufügen von CNN-Schichten\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(SEQ_LENGTH, len(selected_features))))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        # Hinzufügen von LSTM-Schichten\n",
    "        model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Callback to log metrics at the end of each epoch\n",
    "        class MlflowLogger(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                mlflow.log_metric(f\"loss_epoch_{epoch}\", logs[\"loss\"])\n",
    "                mlflow.log_metric(f\"val_loss_epoch_{epoch}\", logs[\"val_loss\"])\n",
    "\n",
    "        # Modell trainieren und Verlaufsdaten speichern\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[MlflowLogger()]\n",
    "        )\n",
    "\n",
    "        # Modell bewerten\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss}')\n",
    "        print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "        # MLflow-Logging\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5089 - loss: 1083891.6250 - val_accuracy: 0.5123 - val_loss: 7.3505\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4913 - loss: 1.1011 - val_accuracy: 0.5325 - val_loss: 0.7346\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5396 - loss: 0.7640 - val_accuracy: 0.5180 - val_loss: 0.7087\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5210 - loss: 0.7149 - val_accuracy: 0.4906 - val_loss: 0.6978\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5329 - loss: 0.6950 - val_accuracy: 0.4877 - val_loss: 0.7052\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5432 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.7059\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5449 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.7022\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5447 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5571 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5439 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7125\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5473 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5458 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5144 - loss: 0.6928 - val_accuracy: 0.4877 - val_loss: 0.7044\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5454 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5472 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.7068\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5490 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5133 - loss: 0.6936 - val_accuracy: 0.4877 - val_loss: 0.7223\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5627 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5474 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.7109\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5168 - loss: 0.6948 - val_accuracy: 0.4877 - val_loss: 0.7143\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5190 - loss: 0.6943 - val_accuracy: 0.4877 - val_loss: 0.7110\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5564 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5603 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.7034\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5438 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7037\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5495 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6976\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5387 - loss: 0.6915 - val_accuracy: 0.5123 - val_loss: 0.6929\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5066 - loss: 0.6931 - val_accuracy: 0.5123 - val_loss: 0.6930\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: 0.6931 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:05:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6933776140213013\n",
      "Test Accuracy: 0.48563218116760254\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5144 - loss: 7082.8564 - val_accuracy: 0.4805 - val_loss: 0.6934\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5517 - loss: 6.3646 - val_accuracy: 0.4877 - val_loss: 0.7269\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5354 - loss: 0.6940 - val_accuracy: 0.4877 - val_loss: 0.7153\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5511 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.7045\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5503 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5494 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5549 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4958 - loss: 0.6934 - val_accuracy: 0.4877 - val_loss: 0.7011\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5417 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5301 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5580 - loss: 0.6875 - val_accuracy: 0.5123 - val_loss: 0.6928\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5152 - loss: 0.6935 - val_accuracy: 0.4877 - val_loss: 0.6999\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6933\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5143 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5531 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.7043\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5568 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5574 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.7059\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5479 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.7038\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5425 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7017\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5307 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7106\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5177 - loss: 0.6960 - val_accuracy: 0.4877 - val_loss: 0.7069\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.7004\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5413 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5106 - loss: 0.6942 - val_accuracy: 0.4877 - val_loss: 0.7077\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5453 - loss: 0.6932 - val_accuracy: 0.4877 - val_loss: 0.7108\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5239 - loss: 0.6959 - val_accuracy: 0.4877 - val_loss: 0.7079\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5251 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6965 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:06:20 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6937569975852966\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5448 - loss: 10.5596 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5395 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5373 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5440 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5183 - loss: 0.6943 - val_accuracy: 0.4877 - val_loss: 0.7048\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5536 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5707 - loss: 0.6860 - val_accuracy: 0.5123 - val_loss: 0.6930\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5082 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5410 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6972\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5361 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7004\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5426 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5405 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5373 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5429 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.7045\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5412 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5636 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6957\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5604 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.7071\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5455 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5286 - loss: 0.6928 - val_accuracy: 0.4877 - val_loss: 0.7037\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5242 - loss: 0.6950 - val_accuracy: 0.4877 - val_loss: 0.7087\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5409 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.7035\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.7040\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5525 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7039\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5546 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5468 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5397 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7059\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5534 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.7054\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5467 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6964 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:06:40 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6937372088432312\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5273 - loss: 0.8757 - val_accuracy: 0.4877 - val_loss: 0.7028\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5385 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7025\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.7012\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5308 - loss: 0.6925 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5505 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.7044\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5633 - loss: 0.6853 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5369 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5566 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5386 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.7061\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5463 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5430 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5491 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.7023\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5400 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5572 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5519 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5536 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5574 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5302 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5557 - loss: 0.6871 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5578 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5532 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5617 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.7043\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5385 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.7011\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5406 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.7035\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.7015 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:07:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6970061659812927\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5460 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5495 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5380 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.7031\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5458 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5622 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5526 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5344 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.7050\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5406 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5426 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5541 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5435 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5489 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5592 - loss: 0.6865 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.7006\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5705 - loss: 0.6843 - val_accuracy: 0.4877 - val_loss: 0.6974\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5335 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.7014\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5519 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5458 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.7008\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5367 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5751 - loss: 0.6834 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5438 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5378 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5314 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.7016\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5456 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5233 - loss: 0.6930 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6992 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:07:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6954574584960938\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5100 - loss: 0.6937 - val_accuracy: 0.4877 - val_loss: 0.6973\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5396 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5351 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5273 - loss: 0.6924 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5535 - loss: 0.6865 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5578 - loss: 0.6873 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5412 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5400 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5449 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5326 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6974\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5677 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6974\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5462 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5381 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5319 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5602 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5454 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5403 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5539 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5369 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6980\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5318 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5458 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5460 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5513 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5364 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5474 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5501 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5529 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5488 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6945 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:07:45 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6928504109382629\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5427 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5511 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5486 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5439 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5487 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5344 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5573 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5469 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5540 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6959\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5346 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5584 - loss: 0.6850 - val_accuracy: 0.4964 - val_loss: 0.6943\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5562 - loss: 0.6858 - val_accuracy: 0.4834 - val_loss: 0.6937\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5453 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5632 - loss: 0.6841 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5396 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5450 - loss: 0.6851 - val_accuracy: 0.4921 - val_loss: 0.6944\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5442 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5475 - loss: 0.6867 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5580 - loss: 0.6849 - val_accuracy: 0.4964 - val_loss: 0.6939\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5421 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5359 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5522 - loss: 0.6849 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5649 - loss: 0.6832 - val_accuracy: 0.4921 - val_loss: 0.6940\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5414 - loss: 0.6852 - val_accuracy: 0.4949 - val_loss: 0.6939\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5317 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5481 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5673 - loss: 0.6851 - val_accuracy: 0.4921 - val_loss: 0.6941\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4933 - loss: 0.6938 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:08:07 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6932125687599182\n",
      "Test Accuracy: 0.5114942789077759\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5435 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5611 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5524 - loss: 0.6873 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5255 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5323 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5340 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5509 - loss: 0.6871 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5329 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5460 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5579 - loss: 0.6849 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5536 - loss: 0.6867 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5551 - loss: 0.6849 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5611 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5350 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5702 - loss: 0.6839 - val_accuracy: 0.4877 - val_loss: 0.6937\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5526 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5383 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5614 - loss: 0.6829 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5529 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5622 - loss: 0.6851 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5469 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5295 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5709 - loss: 0.6833 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5480 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5565 - loss: 0.6836 - val_accuracy: 0.4949 - val_loss: 0.6937\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5485 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5361 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5590 - loss: 0.6846 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5485 - loss: 0.6859 - val_accuracy: 0.4906 - val_loss: 0.6950\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4979 - loss: 0.6942 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:08:33 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6930581331253052\n",
      "Test Accuracy: 0.5258620977401733\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5369 - loss: 0.6897 - val_accuracy: 0.4820 - val_loss: 0.6935\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5693 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5506 - loss: 0.6869 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5382 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5476 - loss: 0.6861 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5438 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5259 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5322 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5603 - loss: 0.6845 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5449 - loss: 0.6860 - val_accuracy: 0.4921 - val_loss: 0.6937\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5444 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5414 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5589 - loss: 0.6859 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5581 - loss: 0.6841 - val_accuracy: 0.4776 - val_loss: 0.6933\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5573 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5379 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5502 - loss: 0.6848 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5459 - loss: 0.6866 - val_accuracy: 0.4978 - val_loss: 0.6940\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5440 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5502 - loss: 0.6869 - val_accuracy: 0.4978 - val_loss: 0.6944\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5470 - loss: 0.6853 - val_accuracy: 0.5007 - val_loss: 0.6937\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5430 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5437 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5499 - loss: 0.6874 - val_accuracy: 0.4892 - val_loss: 0.6940\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5309 - loss: 0.6877 - val_accuracy: 0.4892 - val_loss: 0.6946\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5441 - loss: 0.6854 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5384 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5468 - loss: 0.6847 - val_accuracy: 0.4892 - val_loss: 0.6948\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5448 - loss: 0.6855 - val_accuracy: 0.4978 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5565 - loss: 0.6850 - val_accuracy: 0.5022 - val_loss: 0.6943\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4964 - loss: 0.6935 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:08:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6929434537887573\n",
      "Test Accuracy: 0.5201149582862854\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5303 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.7034\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5507 - loss: 0.6868 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5381 - loss: 0.6889 - val_accuracy: 0.4848 - val_loss: 0.6942\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5294 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5576 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5334 - loss: 0.6918 - val_accuracy: 0.4863 - val_loss: 0.6969\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5477 - loss: 0.6871 - val_accuracy: 0.4820 - val_loss: 0.6953\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5406 - loss: 0.6895 - val_accuracy: 0.4820 - val_loss: 0.6951\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5487 - loss: 0.6856 - val_accuracy: 0.4892 - val_loss: 0.6948\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5308 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5417 - loss: 0.6861 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5481 - loss: 0.6869 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5563 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5471 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5312 - loss: 0.6900 - val_accuracy: 0.4892 - val_loss: 0.6946\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5393 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5450 - loss: 0.6851 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5435 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5403 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5403 - loss: 0.6864 - val_accuracy: 0.4834 - val_loss: 0.6935\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5484 - loss: 0.6863 - val_accuracy: 0.4964 - val_loss: 0.6945\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5325 - loss: 0.6883 - val_accuracy: 0.4921 - val_loss: 0.6948\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5475 - loss: 0.6885 - val_accuracy: 0.4820 - val_loss: 0.6944\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5432 - loss: 0.6861 - val_accuracy: 0.4863 - val_loss: 0.6955\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5440 - loss: 0.6879 - val_accuracy: 0.4834 - val_loss: 0.6949\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5451 - loss: 0.6885 - val_accuracy: 0.4848 - val_loss: 0.6942\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5517 - loss: 0.6864 - val_accuracy: 0.4776 - val_loss: 0.6938\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5402 - loss: 0.6878 - val_accuracy: 0.4820 - val_loss: 0.6945\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5444 - loss: 0.6853 - val_accuracy: 0.4791 - val_loss: 0.6940\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5467 - loss: 0.6842 - val_accuracy: 0.4820 - val_loss: 0.6940\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4954 - loss: 0.6933 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 13:09:25 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.693146824836731\n",
      "Test Accuracy: 0.4913793206214905\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Zielvariablen für die Vorhersage erstellen\n",
    "data['Target'] = (data['Close'] <= data['Previous_Close']).astype(int)\n",
    "\n",
    "data_clean = data\n",
    "data_clean.dropna(inplace=True)\n",
    "data_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Auswahl und Skalierung der relevanten Features\n",
    "selected_features = ['Close', 'RSI', 'EMA20', 'Bollinger_Middle', 'MACD', 'Previous_Close']\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = sc.fit_transform(data[selected_features])\n",
    "\n",
    "def create_sequences(features, target, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequence = features[i:i + seq_length]\n",
    "        label = target[i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Hyperparameter-Definition\n",
    "learning_rates = [0.1, 0.075, 0.05, 0.025, 0.01, 0.0075, 0.005, 0.0025, 0.001, 0.00075]\n",
    "SEQ_LENGTH = 30  # Konstante Sequenzlänge\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seq_length\": SEQ_LENGTH\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Daten vorbereiten basierend auf der aktuellen seq_length\n",
    "        X, y = create_sequences(scaled_features, data['Target'].values, SEQ_LENGTH)\n",
    "\n",
    "        # Datenaufteilung: 70% Training, 20% Validierung, 10% Test\n",
    "        train_size = int(0.7 * len(X))\n",
    "        val_size = int(0.2 * len(X))\n",
    "        test_size = len(X) - train_size - val_size\n",
    "\n",
    "        X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "        y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "        # Umformung der Daten für CNN-LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "        # Modellarchitektur definieren\n",
    "        model = Sequential()\n",
    "        # Hinzufügen von CNN-Schichten\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(SEQ_LENGTH, len(selected_features))))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        # Hinzufügen von LSTM-Schichten\n",
    "        model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Callback to log metrics at the end of each epoch\n",
    "        class MlflowLogger(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                mlflow.log_metric(f\"loss_epoch_{epoch}\", logs[\"loss\"])\n",
    "                mlflow.log_metric(f\"val_loss_epoch_{epoch}\", logs[\"val_loss\"])\n",
    "                mlflow.log_metric(f\"accuracy_epoch_{epoch}\", logs[\"accuracy\"])\n",
    "                mlflow.log_metric(f\"val_accuracy_epoch_{epoch}\", logs[\"val_accuracy\"])\n",
    "\n",
    "        # Modell trainieren und Verlaufsdaten speichern\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[MlflowLogger()]\n",
    "        )\n",
    "\n",
    "        # Modell bewerten\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss}')\n",
    "        print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "        # MLflow-Logging\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "# Extrahiere die Ergebnisse und plotte Learning Rate vs. Accuracy\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "all_history = {}\n",
    "\n",
    "for run in runs:\n",
    "    learning_rate = float(run.data.params['learning_rate'])\n",
    "    accuracy_history = [run.data.metrics[f'accuracy_epoch_{epoch}'] for epoch in range(EPOCHS)]\n",
    "    all_history[learning_rate] = accuracy_history\n",
    "\n",
    "# Plotten des Verlaufs der Genauigkeit für jede Lernrate\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for lr, accuracy_history in all_history.items():\n",
    "    plt.plot(range(1, len(accuracy_history) + 1), accuracy_history, label=f'LR={lr}')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy per Epoch for Different Learning Rates')\n",
    "plt.ylim(0.68, 0.7)  # Setze den Bereich der y-Achse von 0.68 bis 0.7\n",
    "plt.xticks(np.arange(1, 31, 1))  # Setze die x-Achse von 1 bis 30\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Loss Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5300 - loss: 127.4955 - val_accuracy: 0.4877 - val_loss: 0.7107\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5311 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7140\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5548 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.7048\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5377 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6934\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5391 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5444 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.7021\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 0.6926 - val_accuracy: 0.4877 - val_loss: 0.6938\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5418 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.7055\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5289 - loss: 0.6956 - val_accuracy: 0.4877 - val_loss: 0.7021\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5373 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5435 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5467 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5468 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7023\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 0.6944 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5328 - loss: 0.6936 - val_accuracy: 0.4877 - val_loss: 0.7087\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5343 - loss: 0.6939 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 0.6878 - val_accuracy: 0.5123 - val_loss: 0.6930\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5157 - loss: 0.6922 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5472 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.7155\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 0.6922 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4835 - loss: 0.6964 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5366 - loss: 0.6918 - val_accuracy: 0.5123 - val_loss: 0.6934\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5115 - loss: 0.6938 - val_accuracy: 0.4877 - val_loss: 0.7053\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5203 - loss: 0.6934 - val_accuracy: 0.4877 - val_loss: 0.7034\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5301 - loss: 0.6920 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5418 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5165 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.7041\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5534 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.7100\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5509 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6981 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:20:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6946921348571777\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5351 - loss: 109596.8672 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5587 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5532 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.7030\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5377 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.7097\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5423 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.7075\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5505 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.7050\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5459 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.7024\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5447 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6934\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5587 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5130 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.7044\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5411 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5412 - loss: 0.6924 - val_accuracy: 0.4877 - val_loss: 0.7074\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5617 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.7058\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 0.6933 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5366 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5424 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4954 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.7048\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 0.6959 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5417 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5467 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7037\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5647 - loss: 0.6865 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5428 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.7036\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5285 - loss: 0.6940 - val_accuracy: 0.4877 - val_loss: 0.7182\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5474 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5352 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5506 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6934\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5193 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6956 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:21:01 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6933221817016602\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5262 - loss: 4.6740 - val_accuracy: 0.4877 - val_loss: 0.7012\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5567 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5362 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7091\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5418 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6973\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5474 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.7054\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5415 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5521 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5468 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6980\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5332 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.7029\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5526 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5600 - loss: 0.6864 - val_accuracy: 0.5123 - val_loss: 0.6930\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5352 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6938\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5327 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.7066\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5531 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6933\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5269 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.7157\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 0.6920 - val_accuracy: 0.4877 - val_loss: 0.6987\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5478 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7035\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5389 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.7041\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5237 - loss: 0.6943 - val_accuracy: 0.4877 - val_loss: 0.7021\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5542 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5457 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5504 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.7023\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5606 - loss: 0.6861 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5361 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.7077\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5316 - loss: 0.6949 - val_accuracy: 0.4877 - val_loss: 0.7114\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5508 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5491 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5424 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5239 - loss: 0.6926 - val_accuracy: 0.4877 - val_loss: 0.7125\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5344 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4959 - loss: 0.6936 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:21:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6927446722984314\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5330 - loss: 0.7046 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5504 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5380 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5485 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5539 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5425 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5435 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5342 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.7060\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5499 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6987\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5439 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5343 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5337 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.7031\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5526 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5369 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5383 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7022\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5445 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5451 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5577 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5482 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5406 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5551 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.7043\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5476 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5460 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.7060\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5263 - loss: 0.6943 - val_accuracy: 0.4877 - val_loss: 0.7061\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5348 - loss: 0.6933 - val_accuracy: 0.4877 - val_loss: 0.7061\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5541 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6976\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5534 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6951 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:21:40 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6930931210517883\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5325 - loss: 0.6922 - val_accuracy: 0.4877 - val_loss: 0.6959\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5514 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5353 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7019\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5462 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5423 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5550 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5403 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.7017\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5589 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6980\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5431 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5508 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5496 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5454 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7003\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5360 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6999\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.7004\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5598 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5441 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.7003\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5371 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5389 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5644 - loss: 0.6855 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5480 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5346 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5422 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.7011\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5378 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.7006\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5564 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5401 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5649 - loss: 0.6854 - val_accuracy: 0.4877 - val_loss: 0.6980\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5478 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5352 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6989 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:22:00 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6952151656150818\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5381 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6980\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5369 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6999\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5498 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6976\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5464 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5369 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7008\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5480 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6976\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5493 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5474 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5425 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5606 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5457 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5491 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.7025\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5455 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5495 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7017\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5520 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.7003\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5304 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5515 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5514 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5524 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5501 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5422 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5451 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5555 - loss: 0.6872 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5457 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5279 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5453 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5481 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5671 - loss: 0.6850 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6966 \n",
      "Test Loss: 0.6938478350639343\n",
      "Test Accuracy: 0.5143678188323975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:22:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5096 - loss: 0.6928 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5397 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5430 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5445 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6987\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5202 - loss: 0.6936 - val_accuracy: 0.4877 - val_loss: 0.7003\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5526 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5605 - loss: 0.6866 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5294 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5482 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6978\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5557 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5538 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6973\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5227 - loss: 0.6933 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5511 - loss: 0.6865 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5374 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5495 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5559 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5554 - loss: 0.6850 - val_accuracy: 0.4877 - val_loss: 0.6957\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5571 - loss: 0.6849 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 0.6854 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5478 - loss: 0.6861 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5508 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5483 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6938\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 0.6859 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6946 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:22:42 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6930498480796814\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5364 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5483 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.7084\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 0.6953 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5303 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5431 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5601 - loss: 0.6848 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5391 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5570 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5537 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5447 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5490 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5632 - loss: 0.6846 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5503 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5551 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5478 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 0.6843 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5513 - loss: 0.6859 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5438 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5293 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5445 - loss: 0.6853 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5409 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5336 - loss: 0.6859 - val_accuracy: 0.4877 - val_loss: 0.6972\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5478 - loss: 0.6861 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5478 - loss: 0.6841 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5325 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 0.6854 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5597 - loss: 0.6831 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6941 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:23:03 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6927763223648071\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5334 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6959\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5533 - loss: 0.6883 - val_accuracy: 0.4863 - val_loss: 0.6941\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5410 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5471 - loss: 0.6877 - val_accuracy: 0.4863 - val_loss: 0.6956\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5507 - loss: 0.6886 - val_accuracy: 0.4834 - val_loss: 0.6945\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5496 - loss: 0.6876 - val_accuracy: 0.4863 - val_loss: 0.6944\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5508 - loss: 0.6884 - val_accuracy: 0.4834 - val_loss: 0.6944\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5330 - loss: 0.6890 - val_accuracy: 0.4892 - val_loss: 0.6949\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6902 - val_accuracy: 0.4921 - val_loss: 0.6949\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5593 - loss: 0.6845 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5438 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5565 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5371 - loss: 0.6904 - val_accuracy: 0.4921 - val_loss: 0.6941\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5313 - loss: 0.6916 - val_accuracy: 0.4892 - val_loss: 0.6942\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5463 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5467 - loss: 0.6865 - val_accuracy: 0.4964 - val_loss: 0.6944\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5324 - loss: 0.6905 - val_accuracy: 0.4921 - val_loss: 0.6944\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5411 - loss: 0.6880 - val_accuracy: 0.4921 - val_loss: 0.6946\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5570 - loss: 0.6828 - val_accuracy: 0.4993 - val_loss: 0.6940\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 0.6861 - val_accuracy: 0.4820 - val_loss: 0.6942\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5642 - loss: 0.6856 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5545 - loss: 0.6862 - val_accuracy: 0.4921 - val_loss: 0.6941\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5598 - loss: 0.6857 - val_accuracy: 0.4791 - val_loss: 0.6943\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5581 - loss: 0.6850 - val_accuracy: 0.4935 - val_loss: 0.6938\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5245 - loss: 0.6897 - val_accuracy: 0.4892 - val_loss: 0.6960\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5360 - loss: 0.6901 - val_accuracy: 0.4964 - val_loss: 0.6950\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5585 - loss: 0.6832 - val_accuracy: 0.4820 - val_loss: 0.6945\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 0.6888 - val_accuracy: 0.4892 - val_loss: 0.6951\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5466 - loss: 0.6842 - val_accuracy: 0.4921 - val_loss: 0.6945\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 0.6880 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4949 - loss: 0.6940 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:23:24 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.692609965801239\n",
      "Test Accuracy: 0.5143678188323975\n",
      "Epoch 1/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5452 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5543 - loss: 0.6865 - val_accuracy: 0.4834 - val_loss: 0.6935\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.6887 - val_accuracy: 0.4993 - val_loss: 0.6942\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5547 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5479 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5521 - loss: 0.6863 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5459 - loss: 0.6893 - val_accuracy: 0.4949 - val_loss: 0.6945\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5277 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5415 - loss: 0.6916 - val_accuracy: 0.4935 - val_loss: 0.6948\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5502 - loss: 0.6873 - val_accuracy: 0.4921 - val_loss: 0.6947\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5466 - loss: 0.6875 - val_accuracy: 0.4834 - val_loss: 0.6939\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5538 - loss: 0.6866 - val_accuracy: 0.4863 - val_loss: 0.6943\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5453 - loss: 0.6882 - val_accuracy: 0.4834 - val_loss: 0.6937\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5473 - loss: 0.6881 - val_accuracy: 0.4863 - val_loss: 0.6940\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5684 - loss: 0.6855 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5379 - loss: 0.6882 - val_accuracy: 0.4892 - val_loss: 0.6943\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5538 - loss: 0.6865 - val_accuracy: 0.4834 - val_loss: 0.6940\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5610 - loss: 0.6834 - val_accuracy: 0.4921 - val_loss: 0.6942\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5375 - loss: 0.6900 - val_accuracy: 0.4978 - val_loss: 0.6951\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 0.6875 - val_accuracy: 0.4863 - val_loss: 0.6946\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5587 - loss: 0.6838 - val_accuracy: 0.4935 - val_loss: 0.6940\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5558 - loss: 0.6858 - val_accuracy: 0.4863 - val_loss: 0.6942\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5199 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6959\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5515 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5454 - loss: 0.6876 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5474 - loss: 0.6875 - val_accuracy: 0.4863 - val_loss: 0.6942\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5683 - loss: 0.6820 - val_accuracy: 0.4906 - val_loss: 0.6941\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5576 - loss: 0.6852 - val_accuracy: 0.4863 - val_loss: 0.6941\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5266 - loss: 0.6892 - val_accuracy: 0.4892 - val_loss: 0.6946\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5417 - loss: 0.6884 - val_accuracy: 0.4964 - val_loss: 0.6947\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 0.6938 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:23:46 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6928000450134277\n",
      "Test Accuracy: 0.5201149582862854\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Zielvariablen für die Vorhersage erstellen\n",
    "data['Target'] = (data['Close'] <= data['Previous_Close']).astype(int)\n",
    "\n",
    "data_clean = data\n",
    "data_clean.dropna(inplace=True)\n",
    "data_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Auswahl und Skalierung der relevanten Features\n",
    "selected_features = ['Close', 'RSI', 'EMA20', 'Bollinger_Middle', 'MACD', 'Previous_Close']\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = sc.fit_transform(data[selected_features])\n",
    "\n",
    "def create_sequences(features, target, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequence = features[i:i + seq_length]\n",
    "        label = target[i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Hyperparameter-Definition\n",
    "learning_rates = [0.1, 0.075, 0.05, 0.025, 0.01, 0.0075, 0.005, 0.0025, 0.001, 0.00075]\n",
    "SEQ_LENGTH = 30  # Konstante Sequenzlänge\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seq_length\": SEQ_LENGTH\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Daten vorbereiten basierend auf der aktuellen seq_length\n",
    "        X, y = create_sequences(scaled_features, data['Target'].values, SEQ_LENGTH)\n",
    "\n",
    "        # Datenaufteilung: 70% Training, 20% Validierung, 10% Test\n",
    "        train_size = int(0.7 * len(X))\n",
    "        val_size = int(0.2 * len(X))\n",
    "        test_size = len(X) - train_size - val_size\n",
    "\n",
    "        X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "        y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "        # Umformung der Daten für CNN-LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "        # Modellarchitektur definieren\n",
    "        model = Sequential()\n",
    "        # Hinzufügen von CNN-Schichten\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(SEQ_LENGTH, len(selected_features))))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        # Hinzufügen von LSTM-Schichten\n",
    "        model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Callback to log metrics at the end of each epoch\n",
    "        class MlflowLogger(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                mlflow.log_metric(f\"loss_epoch_{epoch}\", logs[\"loss\"])\n",
    "                mlflow.log_metric(f\"val_loss_epoch_{epoch}\", logs[\"val_loss\"])\n",
    "\n",
    "        # Modell trainieren und Verlaufsdaten speichern\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[MlflowLogger()]\n",
    "        )\n",
    "\n",
    "        # Modell bewerten\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss}')\n",
    "        print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "        # MLflow-Logging\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "# Extrahiere die Ergebnisse und plotte Learning Rate vs. Loss\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "all_history = {}\n",
    "\n",
    "for run in runs:\n",
    "    learning_rate = float(run.data.params['learning_rate'])\n",
    "    loss_history = [run.data.metrics[f'loss_epoch_{epoch}'] for epoch in range(EPOCHS)]\n",
    "    all_history[learning_rate] = loss_history\n",
    "\n",
    "# Plotten des Verlaufs der Verlustfunktion für jede Lernrate\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for lr, loss_history in all_history.items():\n",
    "    plt.plot(range(1, len(loss_history) + 1), loss_history, label=f'LR={lr}')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Function per Epoch for Different Learning Rates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4786 - loss: 10678.0635 - val_accuracy: 0.4906 - val_loss: 0.6968\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5562 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5503 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.7057\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5616 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5254 - loss: 0.6903 - val_accuracy: 0.5123 - val_loss: 0.6930\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5589 - loss: 0.6897 - val_accuracy: 0.4949 - val_loss: 0.6933\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5328 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5510 - loss: 0.6887 - val_accuracy: 0.4993 - val_loss: 0.6935\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5376 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5153 - loss: 0.6944 - val_accuracy: 0.4877 - val_loss: 0.7103\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5383 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5478 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6933\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.7068\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5572 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5433 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.7035\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5450 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.7026\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5292 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5406 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7322\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5497 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5237 - loss: 0.6918 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5403 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5465 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6936\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5198 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6935\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5180 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.7021\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5383 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.7015\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 0.6938 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.6920 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5486 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6957 \n",
      "Test Loss: 0.6933254599571228\n",
      "Test Accuracy: 0.5143678188323975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:09:58 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5129 - loss: 4286.3809 - val_accuracy: 0.4877 - val_loss: 0.6957\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5245 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5456 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5407 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7051\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5504 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5523 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5524 - loss: 0.6885 - val_accuracy: 0.5123 - val_loss: 0.6929\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 0.6909 - val_accuracy: 0.5123 - val_loss: 0.6929\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5067 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.7164\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5456 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.7003\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5317 - loss: 0.6931 - val_accuracy: 0.4877 - val_loss: 0.7070\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5560 - loss: 0.6871 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5473 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5188 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5345 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5493 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5443 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5404 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.7056\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5530 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5425 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6937\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5398 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5402 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5411 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6975\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5483 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5416 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.6973\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5534 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5586 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5389 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7040\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.7055\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.7033 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:10:17 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6983195543289185\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5202 - loss: 10.3437 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6925 - val_accuracy: 0.4877 - val_loss: 0.7096\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5362 - loss: 0.6939 - val_accuracy: 0.4877 - val_loss: 0.7018\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5507 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.7027\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5306 - loss: 0.6930 - val_accuracy: 0.4877 - val_loss: 0.7186\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5477 - loss: 0.6996 - val_accuracy: 0.4877 - val_loss: 0.7010\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5598 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5446 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6972\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5522 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5427 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.7078\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5222 - loss: 0.6924 - val_accuracy: 0.4877 - val_loss: 0.7071\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5356 - loss: 0.6924 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5677 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5466 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5582 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.7013\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5609 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5526 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5451 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6962\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5426 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6974\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5422 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6958\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5525 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5382 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.7074\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5466 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5477 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6963\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5573 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.7016\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5465 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5500 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.7014\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5443 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6969 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:10:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6939685344696045\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5002 - loss: 0.7085 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5238 - loss: 0.6939 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5285 - loss: 0.6928 - val_accuracy: 0.4877 - val_loss: 0.7009\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5343 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5548 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5439 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5569 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.7004\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5492 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.7006\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7034\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5512 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.7013\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5258 - loss: 0.6929 - val_accuracy: 0.4877 - val_loss: 0.7087\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7049\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5424 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.7015\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5527 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5671 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5460 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6967\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5555 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5427 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.7025\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5453 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5461 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5481 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.7015\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5554 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.7028\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5453 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5491 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5288 - loss: 0.6931 - val_accuracy: 0.4877 - val_loss: 0.7027\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5400 - loss: 0.6908 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5361 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7017\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5586 - loss: 0.6869 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5386 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7033\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5512 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:10:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.694149911403656\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5248 - loss: 0.6938 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5479 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5303 - loss: 0.6923 - val_accuracy: 0.4834 - val_loss: 1.5894\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5302 - loss: 0.7183 - val_accuracy: 0.4877 - val_loss: 0.7005\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5414 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5339 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7014\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5567 - loss: 0.6873 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5395 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5291 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.7012\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5517 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5533 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5478 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5417 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.7002\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5356 - loss: 0.6911 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5449 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5352 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7013\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5455 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.6999\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5402 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5516 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5399 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5469 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5547 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.7007\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5614 - loss: 0.6860 - val_accuracy: 0.4877 - val_loss: 0.6989\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5535 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5478 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5485 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6990\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5376 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6994\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 0.6919 - val_accuracy: 0.4877 - val_loss: 0.7015\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5496 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6969 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:11:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.693963348865509\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5334 - loss: 0.6921 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5651 - loss: 0.6841 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5555 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5518 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6970\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5364 - loss: 0.6915 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5306 - loss: 0.6928 - val_accuracy: 0.4877 - val_loss: 0.6973\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5479 - loss: 0.6894 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5294 - loss: 0.6912 - val_accuracy: 0.4877 - val_loss: 0.6971\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5535 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5690 - loss: 0.6850 - val_accuracy: 0.4877 - val_loss: 0.6982\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5490 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5617 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6987\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5603 - loss: 0.6865 - val_accuracy: 0.4877 - val_loss: 0.6984\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5397 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.7000\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5525 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5390 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5336 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.7013\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5617 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5476 - loss: 0.6888 - val_accuracy: 0.4877 - val_loss: 0.6995\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5535 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6983\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5326 - loss: 0.6913 - val_accuracy: 0.4877 - val_loss: 0.6996\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5413 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6993\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5397 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5399 - loss: 0.6902 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.4877 - val_loss: 0.6985\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5462 - loss: 0.6897 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5431 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6991\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5529 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6992\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5392 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6978\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6965 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:11:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.693783700466156\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5621 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5483 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6986\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5487 - loss: 0.6893 - val_accuracy: 0.4877 - val_loss: 0.7001\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5475 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6974\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5369 - loss: 0.6907 - val_accuracy: 0.4877 - val_loss: 0.6981\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5384 - loss: 0.6898 - val_accuracy: 0.4877 - val_loss: 0.6965\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5608 - loss: 0.6856 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5519 - loss: 0.6864 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5476 - loss: 0.6889 - val_accuracy: 0.4877 - val_loss: 0.6968\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5402 - loss: 0.6890 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5645 - loss: 0.6839 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5465 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6956\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5372 - loss: 0.6892 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5251 - loss: 0.6901 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5571 - loss: 0.6852 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5440 - loss: 0.6909 - val_accuracy: 0.4877 - val_loss: 0.6961\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5637 - loss: 0.6840 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5429 - loss: 0.6891 - val_accuracy: 0.4877 - val_loss: 0.6954\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5316 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5451 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5582 - loss: 0.6838 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 0.6887 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5428 - loss: 0.6851 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5495 - loss: 0.6858 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5380 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6987\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5502 - loss: 0.6852 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5546 - loss: 0.6860 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5351 - loss: 0.6880 - val_accuracy: 0.4877 - val_loss: 0.6947\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5402 - loss: 0.6863 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6938 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:11:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6928344964981079\n",
      "Test Accuracy: 0.5143678188323975\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[179   0]\n",
      " [169   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       179\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.51       348\n",
      "   macro avg       0.26      0.50      0.34       348\n",
      "weighted avg       0.26      0.51      0.35       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5252 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5359 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5416 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5328 - loss: 0.6900 - val_accuracy: 0.4877 - val_loss: 0.6977\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5423 - loss: 0.6899 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5487 - loss: 0.6884 - val_accuracy: 0.4906 - val_loss: 0.6949\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5539 - loss: 0.6879 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5410 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6960\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5379 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6964\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5480 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5414 - loss: 0.6883 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5505 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5441 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5443 - loss: 0.6867 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5645 - loss: 0.6849 - val_accuracy: 0.4921 - val_loss: 0.6941\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5528 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6940\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5684 - loss: 0.6844 - val_accuracy: 0.4877 - val_loss: 0.6939\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5491 - loss: 0.6868 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5521 - loss: 0.6852 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5385 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5578 - loss: 0.6842 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5436 - loss: 0.6871 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5580 - loss: 0.6849 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5406 - loss: 0.6864 - val_accuracy: 0.4848 - val_loss: 0.6942\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5531 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5442 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5332 - loss: 0.6884 - val_accuracy: 0.4877 - val_loss: 0.6966\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5350 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5520 - loss: 0.6857 - val_accuracy: 0.4877 - val_loss: 0.6941\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5391 - loss: 0.6880 - val_accuracy: 0.4892 - val_loss: 0.6935\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4904 - loss: 0.6932 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:12:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6930411458015442\n",
      "Test Accuracy: 0.49425286054611206\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[124  55]\n",
      " [121  48]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.58       179\n",
      "           1       0.47      0.28      0.35       169\n",
      "\n",
      "    accuracy                           0.49       348\n",
      "   macro avg       0.49      0.49      0.47       348\n",
      "weighted avg       0.49      0.49      0.47       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4962 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.6969\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 0.6876 - val_accuracy: 0.4906 - val_loss: 0.6937\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5555 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6957\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5189 - loss: 0.6954 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5483 - loss: 0.6873 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5703 - loss: 0.6836 - val_accuracy: 0.4791 - val_loss: 0.6937\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5243 - loss: 0.6903 - val_accuracy: 0.4877 - val_loss: 0.6951\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5636 - loss: 0.6856 - val_accuracy: 0.4921 - val_loss: 0.6947\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5492 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5396 - loss: 0.6895 - val_accuracy: 0.4877 - val_loss: 0.6952\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5402 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5652 - loss: 0.6836 - val_accuracy: 0.5022 - val_loss: 0.6937\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5495 - loss: 0.6882 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5538 - loss: 0.6859 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5435 - loss: 0.6873 - val_accuracy: 0.4863 - val_loss: 0.6949\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5385 - loss: 0.6874 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5432 - loss: 0.6885 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5458 - loss: 0.6865 - val_accuracy: 0.4892 - val_loss: 0.6946\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5292 - loss: 0.6886 - val_accuracy: 0.4877 - val_loss: 0.6955\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5359 - loss: 0.6884 - val_accuracy: 0.4863 - val_loss: 0.6960\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5511 - loss: 0.6852 - val_accuracy: 0.4863 - val_loss: 0.6949\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5593 - loss: 0.6827 - val_accuracy: 0.4863 - val_loss: 0.6941\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5615 - loss: 0.6821 - val_accuracy: 0.5022 - val_loss: 0.6941\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5434 - loss: 0.6862 - val_accuracy: 0.4892 - val_loss: 0.6947\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5478 - loss: 0.6877 - val_accuracy: 0.4791 - val_loss: 0.6947\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5422 - loss: 0.6876 - val_accuracy: 0.4791 - val_loss: 0.6953\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5462 - loss: 0.6871 - val_accuracy: 0.4892 - val_loss: 0.6956\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5436 - loss: 0.6852 - val_accuracy: 0.4949 - val_loss: 0.6946\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5478 - loss: 0.6837 - val_accuracy: 0.4805 - val_loss: 0.6945\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5545 - loss: 0.6865 - val_accuracy: 0.4762 - val_loss: 0.6948\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 0.6936 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:12:25 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6924943327903748\n",
      "Test Accuracy: 0.517241358757019\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[157  22]\n",
      " [146  23]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.65       179\n",
      "           1       0.51      0.14      0.21       169\n",
      "\n",
      "    accuracy                           0.52       348\n",
      "   macro avg       0.51      0.51      0.43       348\n",
      "weighted avg       0.51      0.52      0.44       348\n",
      "\n",
      "X_train shape: (2426, 30, 6)\n",
      "X_val shape: (693, 30, 6)\n",
      "X_test shape: (348, 30, 6)\n",
      "Reshaped X_train shape: (2426, 30, 6)\n",
      "Reshaped X_val shape: (693, 30, 6)\n",
      "Reshaped X_test shape: (348, 30, 6)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WWI2021\\Semester 6\\Machine Learning Project\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5368 - loss: 0.6906 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 2/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5448 - loss: 0.6885 - val_accuracy: 0.4877 - val_loss: 0.6945\n",
      "Epoch 3/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5574 - loss: 0.6847 - val_accuracy: 0.4877 - val_loss: 0.6944\n",
      "Epoch 4/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5566 - loss: 0.6870 - val_accuracy: 0.4877 - val_loss: 0.6938\n",
      "Epoch 5/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5371 - loss: 0.6896 - val_accuracy: 0.4877 - val_loss: 0.6950\n",
      "Epoch 6/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5464 - loss: 0.6862 - val_accuracy: 0.4877 - val_loss: 0.6948\n",
      "Epoch 7/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5472 - loss: 0.6877 - val_accuracy: 0.4877 - val_loss: 0.6953\n",
      "Epoch 8/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5478 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 9/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5560 - loss: 0.6871 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 10/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5456 - loss: 0.6878 - val_accuracy: 0.4863 - val_loss: 0.6944\n",
      "Epoch 11/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5408 - loss: 0.6868 - val_accuracy: 0.4993 - val_loss: 0.6944\n",
      "Epoch 12/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5538 - loss: 0.6875 - val_accuracy: 0.4892 - val_loss: 0.6943\n",
      "Epoch 13/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5488 - loss: 0.6866 - val_accuracy: 0.4805 - val_loss: 0.6935\n",
      "Epoch 14/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5361 - loss: 0.6882 - val_accuracy: 0.4762 - val_loss: 0.6948\n",
      "Epoch 15/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5354 - loss: 0.6894 - val_accuracy: 0.4892 - val_loss: 0.6948\n",
      "Epoch 16/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5431 - loss: 0.6873 - val_accuracy: 0.4877 - val_loss: 0.6946\n",
      "Epoch 17/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5530 - loss: 0.6840 - val_accuracy: 0.4791 - val_loss: 0.6937\n",
      "Epoch 18/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5481 - loss: 0.6871 - val_accuracy: 0.4892 - val_loss: 0.6945\n",
      "Epoch 19/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5623 - loss: 0.6807 - val_accuracy: 0.4877 - val_loss: 0.6936\n",
      "Epoch 20/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 0.6881 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 21/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5462 - loss: 0.6849 - val_accuracy: 0.5022 - val_loss: 0.6936\n",
      "Epoch 22/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5598 - loss: 0.6857 - val_accuracy: 0.4892 - val_loss: 0.6938\n",
      "Epoch 23/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5501 - loss: 0.6866 - val_accuracy: 0.4978 - val_loss: 0.6939\n",
      "Epoch 24/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 0.6869 - val_accuracy: 0.4877 - val_loss: 0.6943\n",
      "Epoch 25/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5556 - loss: 0.6867 - val_accuracy: 0.4863 - val_loss: 0.6939\n",
      "Epoch 26/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5495 - loss: 0.6877 - val_accuracy: 0.4978 - val_loss: 0.6944\n",
      "Epoch 27/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5407 - loss: 0.6866 - val_accuracy: 0.4978 - val_loss: 0.6941\n",
      "Epoch 28/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5345 - loss: 0.6885 - val_accuracy: 0.4892 - val_loss: 0.6952\n",
      "Epoch 29/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5454 - loss: 0.6865 - val_accuracy: 0.4892 - val_loss: 0.6940\n",
      "Epoch 30/30\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5526 - loss: 0.6835 - val_accuracy: 0.4834 - val_loss: 0.6938\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4847 - loss: 0.6935 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 12:12:44 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6933080554008484\n",
      "Test Accuracy: 0.48563218116760254\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Confusion Matrix\n",
      "[[110  69]\n",
      " [110  59]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55       179\n",
      "           1       0.46      0.35      0.40       169\n",
      "\n",
      "    accuracy                           0.49       348\n",
      "   macro avg       0.48      0.48      0.47       348\n",
      "weighted avg       0.48      0.49      0.48       348\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAIoCAYAAAAP7ogRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1h0lEQVR4nO3dd3hUZfr/8c9kUgmEGkKaCUWkSJEiIiKiFAWVprDIKsqKuwoKZn+KrLsC1lV2FVdUVhRlcXVRRAFBYqSoKCjCVwWliBTpxRASAqTN+f1xnEmGJJAymTPl/bquuXJy5syZe4bkMHfu57kfm2EYhgAAAAAANS7E6gAAAAAAIFiQgAEAAACAl5CAAQAAAICXkIABAAAAgJeQgAEAAACAl5CAAQAAAICXkIABAAAAgJeQgAEAAACAl5CAAQAAAICXkIABAHxSamqqbr/9dqvDAADAo0jAACCAvfHGG7LZbPrmm2+sDsWv2Gw2t1tMTIx69eqlpUuXVvmcb731lmbMmOG5IL3kqquu0sUXX2x1GAAQMEKtDgAAgLJs27ZNISHW/Z2wb9++uu2222QYhvbs2aOXX35ZN9xwgz766CP179+/0ud76623tHnzZk2cONHzwQIA/AYJGACgxhUWFsrhcCg8PLzCj4mIiKjBiM6vZcuW+v3vf+/6ftiwYWrTpo2ef/75KiVgAABIDEEEAEjav3+/xowZo7i4OEVERKht27aaM2eO2zH5+fl65JFH1LlzZ9WtW1fR0dHq2bOnVq1a5Xbc7t27ZbPZ9I9//EMzZsxQ8+bNFRERoR9//FFTp06VzWbTjh07dPvtt6tevXqqW7eu7rjjDp06dcrtPGfPAXMOp/ziiy+Ulpam2NhYRUdHa8iQITp69KjbYx0Oh6ZOnaqEhATVqlVLvXv31o8//liteWWtW7dWo0aN9PPPP7vtX7RokQYOHKiEhARFRESoefPmeuyxx1RUVOQ65qqrrtLSpUu1Z88e17DG1NRU1/15eXmaMmWKWrRooYiICCUnJ+vBBx9UXl7eOWMaP368ateuXeq9k6SRI0eqSZMmrji++eYb9e/fX40aNVJUVJSaNm2qMWPGVOm9KMtLL72ktm3bKiIiQgkJCRo3bpyysrLcjvnpp580bNgwNWnSRJGRkUpKStLvfvc7nThxwnVMRkaGrrjiCtWrV0+1a9fWRRddpL/85S8eixMArEYFDACC3OHDh3XZZZfJZrNp/Pjxio2N1UcffaQ//OEPys7Odg2Zy87O1quvvqqRI0dq7NixysnJ0Wuvvab+/fvr66+/VseOHd3O+/rrr+vMmTO66667FBERoQYNGrjuGz58uJo2baqnnnpKGzdu1KuvvqrGjRvr6aefPm+89957r+rXr68pU6Zo9+7dmjFjhsaPH6/58+e7jpk8ebKeeeYZ3XDDDerfv7++++479e/fX2fOnKny+3TixAkdP35czZs3d9v/xhtvqHbt2kpLS1Pt2rW1cuVKPfLII8rOztb06dMlSQ8//LBOnDihffv26bnnnpMk1a5dW5KZLN54441as2aN7rrrLrVu3VqbNm3Sc889p+3bt+uDDz4oN6YRI0boxRdf1NKlS3XzzTe79p86dUpLlizR7bffLrvdriNHjqhfv36KjY3VQw89pHr16mn37t1auHBhld+PkqZOnapp06apT58+uvvuu7Vt2za9/PLLWr9+vb744guFhYUpPz9f/fv3V15enu699141adJE+/fv14cffqisrCzVrVtXP/zwg66//nq1b99ejz76qCIiIrRjxw598cUXHokTAHyCAQAIWK+//rohyVi/fn25x/zhD38w4uPjjWPHjrnt/93vfmfUrVvXOHXqlGEYhlFYWGjk5eW5HXP8+HEjLi7OGDNmjGvfrl27DElGTEyMceTIEbfjp0yZYkhyO94wDGPIkCFGw4YN3falpKQYo0ePLvVa+vTpYzgcDtf++++/37Db7UZWVpZhGIZx6NAhIzQ01Bg8eLDb+aZOnWpIcjtneSQZf/jDH4yjR48aR44cMb755hvj2muvNSQZ06dPdzvW+f6U9Mc//tGoVauWcebMGde+gQMHGikpKaWOnTdvnhESEmJ8/vnnbvtnzZplSDK++OKLcuN0OBxGYmKiMWzYMLf977zzjiHJ+OyzzwzDMIz333//vD8H5enVq5fRtm3bcu8/cuSIER4ebvTr188oKipy7Z85c6YhyZgzZ45hGIbxf//3f4Yk49133y33XM8995whyTh69Gil4wQAf8EQRAAIYoZh6L333tMNN9wgwzB07Ngx161///46ceKENm7cKEmy2+2uOVwOh0OZmZkqLCxUly5dXMeUNGzYMMXGxpb5vH/605/cvu/Zs6d+/fVXZWdnnzfmu+66Szabze2xRUVF2rNnjyRpxYoVKiws1D333OP2uHvvvfe85y7ptddeU2xsrBo3bqwuXbpoxYoVevDBB5WWluZ2XFRUlGs7JydHx44dU8+ePXXq1Clt3br1vM/z7rvvqnXr1mrVqpXb+3/11VdLUqkhniXZbDbdfPPNWrZsmU6ePOnaP3/+fCUmJuqKK66QJNWrV0+S9OGHH6qgoKDC70FFfPLJJ8rPz9fEiRPdmqaMHTtWMTExrs6RdevWlSSlp6eXOWSyZJyLFi2Sw+HwaJwA4CtIwAAgiB09elRZWVl65ZVXFBsb63a74447JElHjhxxHT937ly1b99ekZGRatiwoWJjY7V06VK3OTxOTZs2Lfd5L7jgArfv69evL0k6fvz4eWM+32OdiViLFi3cjmvQoIHr2IoYNGiQMjIytHTpUtfctVOnTpXqzPjDDz9oyJAhqlu3rmJiYhQbG+tq3lHW+3K2n376ST/88EOp979ly5aS3N//sowYMUKnT5/W4sWLJUknT57UsmXLdPPNN7sS1V69emnYsGGaNm2aGjVqpEGDBun1118/7xyzinC+3xdddJHb/vDwcDVr1sx1f9OmTZWWlqZXX31VjRo1Uv/+/fXiiy+6vUcjRoxQjx49dOeddyouLk6/+93v9M4775CMAQgozAEDgCDm/GD7+9//XqNHjy7zmPbt20uS3nzzTd1+++0aPHiwHnjgATVu3Fh2u11PPfVUqcYUkntl6Gx2u73M/YZhnDfm6jy2MpKSktSnTx9J0oABA9SoUSONHz9evXv31tChQyVJWVlZ6tWrl2JiYvToo4+qefPmioyM1MaNGzVp0qQKJQ4Oh0Pt2rXTs88+W+b9ycnJ53z8ZZddptTUVL3zzju65ZZbtGTJEp0+fVojRoxwHWOz2bRgwQKtW7dOS5YsUXp6usaMGaN//vOfWrdunWs+Wk375z//qdtvv12LFi3Sxx9/rPvuu09PPfWU1q1bp6SkJEVFRemzzz7TqlWrtHTpUi1fvlzz58/X1VdfrY8//rjcf3sA8CckYAAQxGJjY1WnTh0VFRW5ko3yLFiwQM2aNdPChQvdhgBOmTKlpsOslJSUFEnSjh073Kpwv/76a4UqbOX54x//qOeee05//etfNWTIENlsNq1evVq//vqrFi5cqCuvvNJ17K5du0o9vuR7VlLz5s313Xff6Zprrin3mPMZPny4nn/+eWVnZ2v+/PlKTU3VZZddVuq4yy67TJdddpmeeOIJvfXWWxo1apT+97//6c4776zS80rF7/e2bdvUrFkz1/78/Hzt2rWr1M9Vu3bt1K5dO/31r3/Vl19+qR49emjWrFl6/PHHJUkhISG65pprdM011+jZZ5/Vk08+qYcfflirVq06788oAPgDhiACQBCz2+0aNmyY3nvvPW3evLnU/SXbuzurDyUrTV999ZXWrl1b84FWwjXXXKPQ0FC9/PLLbvtnzpxZrfOGhobqz3/+s7Zs2aJFixZJKvs9yc/P10svvVTq8dHR0WUOSRw+fLj279+v2bNnl7rv9OnTys3NPW9sI0aMUF5enubOnavly5dr+PDhbvcfP368VIXQ2bWyusMQ+/Tpo/DwcP3rX/9ye47XXntNJ06c0MCBAyWZXTQLCwvdHtuuXTuFhIS4YsjMzCx1fk/FCQC+ggoYAASBOXPmaPny5aX2T5gwQX//+9+1atUqdevWTWPHjlWbNm2UmZmpjRs36pNPPnF9KL7++uu1cOFCDRkyRAMHDtSuXbs0a9YstWnTxq0BhNXi4uI0YcIE/fOf/9SNN96oa6+9Vt99950++ugjNWrUqMpVJkm6/fbb9cgjj+jpp5/W4MGDdfnll6t+/foaPXq07rvvPtlsNs2bN6/M4ZCdO3fW/PnzlZaWpq5du6p27dq64YYbdOutt+qdd97Rn/70J61atUo9evRQUVGRtm7dqnfeeUfp6enq0qXLOePq1KmTWrRooYcfflh5eXluww8lc+7eSy+9pCFDhqh58+bKycnR7NmzFRMTowEDBpz3dR89etRVoSqpadOmGjVqlCZPnqxp06bp2muv1Y033qht27bppZdeUteuXV3z4VauXKnx48fr5ptvVsuWLVVYWKh58+a5/gggSY8++qg+++wzDRw4UCkpKTpy5IheeuklJSUluRqKAIDfs6z/IgCgxjlbt5d327t3r2EYhnH48GFj3LhxRnJyshEWFmY0adLEuOaaa4xXXnnFdS6Hw2E8+eSTRkpKihEREWFccsklxocffmiMHj3arb26sw392e3aDaO4Df3Zbcadce7atcu1r7w29Ge3Ul+1apUhyVi1apVrX2FhofG3v/3NaNKkiREVFWVcffXVxpYtW4yGDRsaf/rTn877vkkyxo0bV+Z9znb2zuf74osvjMsuu8yIiooyEhISjAcffNBIT08vFdPJkyeNW265xahXr54hye09y8/PN55++mmjbdu2RkREhFG/fn2jc+fOxrRp04wTJ06cN17DMIyHH37YkGS0aNGi1H0bN240Ro4caVxwwQVGRESE0bhxY+P66683vvnmm/Oet1evXuX+/FxzzTWu42bOnGm0atXKCAsLM+Li4oy7777bOH78uOv+nTt3GmPGjDGaN29uREZGGg0aNDB69+5tfPLJJ65jVqxYYQwaNMhISEgwwsPDjYSEBGPkyJHG9u3bK/QeAIA/sBmGh2ctAwDgg7KyslS/fn09/vjjevjhh60OBwAQpJgDBgAIOKdPny61b8aMGZKkq666yrvBAABQAnPAAAABZ/78+XrjjTc0YMAA1a5dW2vWrNHbb7+tfv36qUePHlaHBwAIYiRgAICA0759e4WGhuqZZ55Rdna2qzFHWY0kAADwJuaAAQAAAICXMAcMAAAAALyEBAwAAAAAvIQ5YFXkcDh04MAB1alTp1qLegIAAADwb4ZhKCcnRwkJCQoJOXeNiwSsig4cOKDk5GSrwwAAAADgI/bu3aukpKRzHkMCVkV16tSRZL7JMTExFkfjHwoKCvTxxx+rX79+CgsLszocAPBJXCsBoGJ86XqZnZ2t5ORkV45wLiRgVeQcdhgTE0MCVkEFBQWqVauWYmJiLP8lAQBfxbUSACrGF6+XFZmaRBMOAAAAAPASEjAAAAAA8BISMAAAAADwEhIwAAAAAPASEjAAAAAA8BISMAAAAADwEhIwAAAAAPASEjAAAAAA8BISMAAAAADwEhIwAAAAAPASEjAAAAAA8BISMAAAAADwEhIwAAAAAPCSUKsDAAAAAOAbioqkzz+XDh6U4uOlnj0lu93qqAILCRgAAAAALVwoTZgg7dtXvC8pSXr+eWnoUOviCjQMQQQAAACC3MKF0k03uSdfkrR/v7l/4UJr4gpEJGAAAABAECsqMitfhlH6Pue+iRPN41B9JGAAAABAEPv889KVr5IMQ9q71zwO1UcCBgAAAASxgwc9exzOjQQMAAAACGLx8Z49DudGAgYAAAAEsZ49zW6HNlvZ99tsUnKyeRyqjwQMAAAACGJ2u9lqvizOpGzGDNYD8xQSMAAAACDIDR0qLVggxcS4709KMvezDpjnkIABAAAA0NCh0lVXue/bvJnky9NIwAAAAABIkr77zv37AwesiSOQkYABAAAAUFaWtGePuZ2YaH795RfLwglYJGAAAAAAXNWvlBSpfXtze+9e6+IJVKFWBwAAAADAet9+a37t2FGKizO3ScA8jwQMAAAAgKsC1qGDFB5ubjME0fNIwAAAAAC4VcBycsxtKmCexxwwAAAAIMgVFEg//GBud+woXXCBuU0FzPOogAEAAABBbutWKT/fXIg5NVVyOMz9e/dKhiHZbJaGF1CogAEAAABBzjn8sEMHM9lKSjK/P31a+vVXy8IKSCRgAAAAQJBzNuDo2NH8GhFBJ8SaQgIGAAAABLmSFTCn5GTzK/PAPIsEDAAAAAhihuHeAdHJ2YiDCphnkYABAAAAQezAAXOel90utW1bvJ8KWM2wPAF78cUXlZqaqsjISHXr1k1ff/31OY/PysrSuHHjFB8fr4iICLVs2VLLli1z3Z+Tk6OJEycqJSVFUVFRuvzyy7V+/Xq3c5w8eVLjx49XUlKSoqKi1KZNG82aNatGXh8AAADgy5zVr1atpMjI4v1UwGqGpW3o58+fr7S0NM2aNUvdunXTjBkz1L9/f23btk2NGzcudXx+fr769u2rxo0ba8GCBUpMTNSePXtUr1491zF33nmnNm/erHnz5ikhIUFvvvmm+vTpox9//FGJiYmSpLS0NK1cuVJvvvmmUlNT9fHHH+uee+5RQkKCbrzxRm+9fAAAAMByZQ0/lIorYCRgnmVpBezZZ5/V2LFjdccdd7iqULVq1dKcOXPKPH7OnDnKzMzUBx98oB49eig1NVW9evVSh99mC54+fVrvvfeennnmGV155ZVq0aKFpk6dqhYtWujll192nefLL7/U6NGjddVVVyk1NVV33XWXOnTocN7qGwAAABBonB0QSzbgkFiMuaZYVgHLz8/Xhg0bNHnyZNe+kJAQ9enTR2vXri3zMYsXL1b37t01btw4LVq0SLGxsbrllls0adIk2e12FRYWqqioSJEla6eSoqKitGbNGtf3l19+uRYvXqwxY8YoISFBq1ev1vbt2/Xcc8+VG29eXp7y8vJc32dnZ0uSCgoKVFBQUKX3INg43yfeLwAoH9dKAN72f/8XKsmmiy8uVEGB4drfpIkkhenAAUOnTxcq1NKxc6X50vWyMjFY9jYeO3ZMRUVFinMuMPCbuLg4bd26tczH7Ny5UytXrtSoUaO0bNky7dixQ/fcc48KCgo0ZcoU1alTR927d9djjz2m1q1bKy4uTm+//bbWrl2rFi1auM7zwgsv6K677lJSUpJCQ0MVEhKi2bNn68orryw33qeeekrTpk0rtf/jjz9WrVq1qvguBKeMjAyrQwAAn8e1EoA3nD5t188/D5QkHTmSoWXL8l33ORxSaOgNKiwM0X//u1KxsWesCvOcfOF6eerUqQof62N57Lk5HA41btxYr7zyiux2uzp37qz9+/dr+vTpmjJliiRp3rx5GjNmjBITE2W329WpUyeNHDlSGzZscJ3nhRde0Lp167R48WKlpKTos88+07hx45SQkKA+ffqU+dyTJ09WWlqa6/vs7GwlJyerX79+iomJqdkXHiAKCgqUkZGhvn37KiwszOpwAMAnca0E4E3r1tlkGDbFxxu65ZbSn4OTkmzavVtq2fIade9ulD6BhXzpeukcHVcRliVgjRo1kt1u1+HDh932Hz58WE3Memcp8fHxCgsLk91ud+1r3bq1Dh06pPz8fIWHh6t58+b69NNPlZubq+zsbMXHx2vEiBFq1qyZJHOe2F/+8he9//77GjjQzPbbt2+vb7/9Vv/4xz/KTcAiIiIUERFRan9YWJjl/+D+hvcMAM6PayUAb9i82fzasaOtzGtOcrK0e7d04ECofPWS5AvXy8o8v2VNOMLDw9W5c2etWLHCtc/hcGjFihXq3r17mY/p0aOHduzYIYfD4dq3fft2xcfHKzw83O3Y6OhoxcfH6/jx40pPT9egQYMkFc/ZCglxf+l2u93tvAAAAECgK68DohOt6D3P0i6IaWlpmj17tubOnastW7bo7rvvVm5uru644w5J0m233ebWpOPuu+9WZmamJkyYoO3bt2vp0qV68sknNW7cONcx6enpWr58uXbt2qWMjAz17t1brVq1cp0zJiZGvXr10gMPPKDVq1dr165deuONN/Sf//xHQ4YM8e4bAAAAAFiovA6ITizG7HmWzgEbMWKEjh49qkceeUSHDh1Sx44dtXz5cldjjl9++cWtUpWcnKz09HTdf//9at++vRITEzVhwgRNmjTJdcyJEyc0efJk7du3Tw0aNNCwYcP0xBNPuJUF//e//2ny5MkaNWqUMjMzlZKSoieeeEJ/+tOfvPfiAQAAAAsVFUnff29uUwHzHsubcIwfP17jx48v877Vq1eX2te9e3etW7eu3PMNHz5cw4cPP+dzNmnSRK+//nql4gQAAAACyY4d0unTUq1aUomG4W5YjNnzLB2CCAAAAMAazvlf7dpJJXrcuWExZs8jAQMAAACC0PkacEjFFbBjx8xqGaqPBAwAAAAIQudrwCFJ9epJtWub2wxD9AwSMAAAACAIVaQCZrMxD8zTSMAAAACAIHPkiHTwoJlgtWt37mOZB+ZZJGAAAABAkHEOP2zRoniIYXmogHkWCRgAAAAQZCoy/NCJxZg9iwQMAAAACDKVScBYjNmzSMAAAACAIFORDohOVMA8iwQMAAAACCKnT0tbt5rbla2AGUaNhRU0SMAAAACAIPLDD1JRkdSokZSQcP7jk5LMr7m5UlZWjYYWFEjAAAAAgCBScvihzXb+46OipNhYc5thiNVHAgYAAAAEkco04HCiFb3nkIABAAAAQaQqCRiLMXsOCRgAAAAQJByOynVAdKIC5jkkYAAAAECQ2L1bysmRwsOlVq0q/jha0XsOCRgAAAAQJJzVr7ZtpbCwij+OxZg9hwQMAAAACBJVmf8lUQHzJBIwAAAAIEhUNQFzVsD27zfXEEPVkYABAAAAQaIqDTgkKT5estulwkLp8GHPxxVMSMAAAACAIHD8uLRnj7ld2QTMbpcSE81thiFWDwkYAAAAEASc1a/UVKlevco/nlb0nkECBgAAAASBqg4/dGIxZs8gAQMAAACCQFUbcDhRAfMMEjAAAAAgCFQ3AaMC5hkkYAAAAECAy8+XfvzR3K7qEEQqYJ5BAgYAAAAEuK1bzSQsJsZswlEVLMbsGSRgAAAAQIArOfzQZqvaOZxDEI8ckc6c8URUwYkEDAAAAAhw1e2AKEkNGkhRUeb2vn3VjylYkYABAAAAAa66DTgks3LmrIIxD6zqSMAAAACAAGYYnqmASTTi8AQSMAAAACCA7d8v/fqrZLdLbdtW71y0oq8+EjAAAAAggDmHH7ZuLUVGVu9cVMCqjwQMAAAACGCeGn4oUQHzBBIwAAAAIIB5ogGHExWw6iMBAwAAAAJYTSRgVMCqjgQMAAAACFA5OdLPP5vbnhiC6EzAcnKkEyeqf75gRAIGAAAABKhNm8w29AkJUmxs9c8XHW0uyCxRBasqEjAAAAAgQHly+KETizFXDwkYAAAAEKA82QHRiUYc1UMCBgAAAASomqyAMQSxakjAAAAAgABUVGTOAZM8m4BRAaseEjAAAAAgAP30k3T6tFSrltS8uefOSwWsekjAAAAAgADkHH7Yvr1kt3vuvFTAqocEDAAAAAhAzgYcnhx+KLl3QXQ4PHvuYEACBgAAAAQgZwXMkx0QJXNNsZAQqaBAOnLEs+cOBiRgAAAAQACqiQ6IkhQaKsXHm9vMA6s8EjAAAAAgwBw+LB06JNlsUrt2nj8/izFXHQkYAAAAEGCc878uvFCKjvb8+Z2NOKiAVR4JGAAAABBgamr4oRMVsKojAQMAAAACjLMC5ukGHE60oq86EjAAAAAgwHirAsYQxMojAQMAAAACyOnT0tat5nZNJWBUwKqOBAwAAAAIID/8YC6Q3KhRcbt4T3NWwA4dkvLza+Y5AhUJGAAAABBASg4/tNlq5jkaNZIiIyXDkPbvr5nnCFQkYAAAAEAAqen5X5KZ2CUlmdvMA6scEjAAAAAggNR0B0QnWtFXDQkYAAAAECAcjuIErCYrYBKLMVcVCRgAAAAQIHbvlnJypIgI6aKLava5qIBVDQkYAAAAECCc87/atpXCwmr2uaiAVQ0JGAAAABAgvNGAw4kKWNX4RAL24osvKjU1VZGRkerWrZu+/vrrcx6flZWlcePGKT4+XhEREWrZsqWWLVvmuj8nJ0cTJ05USkqKoqKidPnll2v9+vVu57DZbGXepk+fXiOvEQAAAKhp3mrAIbEYc1VZnoDNnz9faWlpmjJlijZu3KgOHTqof//+OnLkSJnH5+fnq2/fvtq9e7cWLFigbdu2afbs2UpMTHQdc+eddyojI0Pz5s3Tpk2b1K9fP/Xp00f7SyxScPDgQbfbnDlzZLPZNGzYsBp/zQAAAEBN8GYFzJmAZWWZ885QMZYnYM8++6zGjh2rO+64Q23atNGsWbNUq1YtzZkzp8zj58yZo8zMTH3wwQfq0aOHUlNT1atXL3X4Lc0/ffq03nvvPT3zzDO68sor1aJFC02dOlUtWrTQyy+/7DpPkyZN3G6LFi1S79691axZM6+8bgAAAMCTMjOL52N5owJWp45Ur565TRWs4kKtfPL8/Hxt2LBBkydPdu0LCQlRnz59tHbt2jIfs3jxYnXv3l3jxo3TokWLFBsbq1tuuUWTJk2S3W5XYWGhioqKFBkZ6fa4qKgorVmzpsxzHj58WEuXLtXcuXPLjTUvL095eXmu77OzsyVJBQUFKigoqPBrDmbO94n3CwDKx7USQFVt3GiTFKrUVEO1ahXKG5eR5ORQZWXZtHNnoS680Kj5JyzBl66XlYnB0gTs2LFjKioqUlxcnNv+uLg4bd26tczH7Ny5UytXrtSoUaO0bNky7dixQ/fcc48KCgo0ZcoU1alTR927d9djjz2m1q1bKy4uTm+//bbWrl2rFi1alHnOuXPnqk6dOho6dGi5sT711FOaNm1aqf0ff/yxatWqVYlXjYyMDKtDAACfx7USQGUtXtxMUjvFxR3SsmXn7qngKRER3SQ10UcfbVZR0R6vPOfZfOF6eerUqQofa2kCVhUOh0ONGzfWK6+8Irvdrs6dO2v//v2aPn26pkyZIkmaN2+exowZo8TERNntdnXq1EkjR47Uhg0byjznnDlzNGrUqFJVs5ImT56stLQ01/fZ2dlKTk5Wv379FBMT49kXGaAKCgqUkZGhvn37Kqym+6ICgJ/iWgmgqt57zy5J6tevsQYMGOCV51y2LETffCPVrdtOAwa09cpzOvnS9dI5Oq4iLE3AGjVqJLvdrsOHD7vtP3z4sJo0aVLmY+Lj4xUWFia73e7a17p1ax06dEj5+fkKDw9X8+bN9emnnyo3N1fZ2dmKj4/XiBEjypzf9fnnn2vbtm2aP3/+OWONiIhQREREqf1hYWGW/4P7G94zADg/rpUAKmvTJvNrp052hYXZz32wh6Smml8PHPDec57NF66XlXl+S5twhIeHq3PnzlqxYoVrn8Ph0IoVK9S9e/cyH9OjRw/t2LFDDofDtW/79u2Kj49XeHi427HR0dGKj4/X8ePHlZ6erkGDBpU632uvvabOnTu7mngAAAAA/iY/X/rhB3PbGx0QnViMufIs74KYlpam2bNna+7cudqyZYvuvvtu5ebm6o477pAk3XbbbW5NOu6++25lZmZqwoQJ2r59u5YuXaonn3xS48aNcx2Tnp6u5cuXa9euXcrIyFDv3r3VqlUr1zmdsrOz9e677+rOO+/0zosFAAAAasCWLVJBgVS3rpSS4r3nZTHmyrN8DtiIESN09OhRPfLIIzp06JA6duyo5cuXuxpz/PLLLwoJKc4Tk5OTlZ6ervvvv1/t27dXYmKiJkyYoEmTJrmOOXHihCZPnqx9+/apQYMGGjZsmJ544olSpcH//e9/MgxDI0eO9M6LBQAAAGpAyQWYbTbvPW/JxZgNw7vP7a8sT8Akafz48Ro/fnyZ961evbrUvu7du2vdunXlnm/48OEaPnz4eZ/3rrvu0l133VXhOAEAAABf5M0FmEtKTDSTrrw86ehRqXFj7z6/P7J8CCIAAACA6nFWwLydgIWHS87eeQxDrBgSMAAAAMCPGUZxBcyKvnLOeWA04qgYEjAAAADAj+3bJ2VmSqGhUps23n/+kvPAcH4kYAAAAIAfcw4/bNVKioz0/vPTir5ySMAAAAAAP2ZVAw4nWtFXDgkYAAAA4MesTsCogFUOCRgAAADgx0quAWYFKmCVQwIGAAAA+KmcHGnHDnPbqgTMWQE7cEAqKLAmBn9CAgYAAAD4qe+/N78mJkqxsdbE0LixuR6YYZhJGM6NBAwAAADwU1YPP5SkkBApKcncZhji+ZGAAQAAAH7K6gYcTizGXHEkYAAAAICf8pUEjMWYK44EDAAAAPBDhYXSpk3mtpVDECUqYJVBAgYAAAD4oZ9+ks6ckaKjpebNrY2FCljFkYABAAAAfsjZgKN9e8lutzYWFmOuOBIwAAAAwA85539ZPfxQYjHmyiABAwAAAPyQrzTgkIorYJmZUm6utbH4OhIwAAAAwA/5whpgTnXrSjEx5jZVsHMjAQMAAAD8zKFD5s1mk9q1szoaE404KoYEDAAAAPAzzupXy5ZmF0RfQCv6iiEBAwAAAPyMLw0/dKICVjEkYAAAAICf8aUGHE5UwCqGBAwAAADwM76YgFEBqxgSMAAAAMCPnD4tbdtmbvviEEQqYOdGAgYAAAD4kc2bJYdDio2V4uOtjqZYycWYDcPaWHwZCRgAAADgR0oOP7TZrIzEXVKS+fX0aenXX62NxZeRgAEAAAB+xBc7IEpSRIQUF2duMw+sfCRgAAAAgB/xxQYcTswDOz8SMAAAAMBPOBzS99+b276YgJWcB4aykYABAAAAfmLXLiknxxzud9FFVkdTGq3oz48EDAAAAPATzuGHF18shYZaGkqZWIz5/EjAAAAAAD/hqw04nKiAnR8JGAAAAOAnfLkBh0QFrCJIwAAAAAA/4esJmLMCduCAVFhobSy+igQMAAAA8AOZmcVD+9q3tzaW8sTFmXPTioqkgwetjsY3kYABAAAAfsA5/6tpU6luXWtjKY/dLiUlmdvMAysbCRgAAADgB3x9+KETizGfGwkYAAAA4Ad8vQOiE4sxnxsJGAAAAOAHqIAFBhIwAAAAwMfl50s//mhu+3oCRgXs3EjAAAAAAB+3ZYtUUCDVq1ec4PgqFmM+NxIwAAAAwMc5hx926CDZbJaGcl4sxnxuJGAAAACAj3M24PD14YdScQXs2DHp9GlrY/FFJGAAAACAjytZAfN19epJ0dHmNsMQSyMBAwAAAHyYYfhPB0TJHCJJI47ykYABAAAAPmzfPun4cSk0VGrTxupoKoZW9OUjAQMAAAB8mLP61bq1FBFhaSgVRgWsfCRgAAAAgA/zp+GHTlTAykcCBgAAAPgwZwdEf2jA4UQFrHwkYAAAAIAP8+cKGAlYaSRgAAAAgI/KzpZ+/tnc9scK2C+/mF0cUYwEDAAAAPBRmzaZXxMTpUaNrI2lMpKSzK+5uVJWlqWh+BwSMAAAAMBH+ePwQ0mKiipOGGnE4Y4EDAAAAPBR/pqASTTiKA8JGAAAAOCj/LEDohOt6MtGAgYAAAD4oMLC4jlgVMACBwkYAAAA4IN++kk6c0aKjpaaN7c6msqjAlY2EjAAAADABznnf7VvL4X44ad2KmBl88N/SgAAACDw+XMDDokKWHlIwAAAAAAf5GzA4a8JmLMCtn+/VFRkbSy+hAQMAAAA8EHOCpg/dkCUpPh4yW43m4kcPmx1NL7D8gTsxRdfVGpqqiIjI9WtWzd9/fXX5zw+KytL48aNU3x8vCIiItSyZUstW7bMdX9OTo4mTpyolJQURUVF6fLLL9f69etLnWfLli268cYbVbduXUVHR6tr1676hfooAAAAfMChQ2bSEhIitWtndTRVY7dLiYnmNh+zi1magM2fP19paWmaMmWKNm7cqA4dOqh///46cuRImcfn5+erb9++2r17txYsWKBt27Zp9uzZSnT+y0q68847lZGRoXnz5mnTpk3q16+f+vTpo/3797uO+fnnn3XFFVeoVatWWr16tb7//nv97W9/U2RkZI2/ZgAAAOB8nMMPL7xQqlXL2liqwzkPjEYcxUKtfPJnn31WY8eO1R133CFJmjVrlpYuXao5c+booYceKnX8nDlzlJmZqS+//FJhYWGSpNTUVNf9p0+f1nvvvadFixbpyiuvlCRNnTpVS5Ys0csvv6zHH39ckvTwww9rwIABeuaZZ1yPbe6PvT0BAAAQkPy9AYcTjThKsywBy8/P14YNGzR58mTXvpCQEPXp00dr164t8zGLFy9W9+7dNW7cOC1atEixsbG65ZZbNGnSJNntdhUWFqqoqKhUJSsqKkpr1qyRJDkcDi1dulQPPvig+vfvr//7v/9T06ZNNXnyZA0ePLjcePPy8pSXl+f6Pjs7W5JUUFCggoKCqr4NQcX5PvF+AUD5uFYCkKSNG+2SQtSuXZEKChxWh1NliYkhkuzas8fzr8OXrpeVicGyBOzYsWMqKipSXFyc2/64uDht3bq1zMfs3LlTK1eu1KhRo7Rs2TLt2LFD99xzjwoKCjRlyhTVqVNH3bt312OPPabWrVsrLi5Ob7/9ttauXasWLVpIko4cOaKTJ0/q73//ux5//HE9/fTTWr58uYYOHapVq1apV69eZT73U089pWnTppXa//HHH6uWP9eFLZCRkWF1CADg87hWAsHtyy+vllRHeXlfa9mysqfn+IPs7KaS2mv9+sNatqx0XwZP8IXr5alTpyp8rM0wDKMGYynXgQMHlJiYqC+//FLdu3d37X/wwQf16aef6quvvir1mJYtW+rMmTPatWuX7Ha7JHMY4/Tp03Xw4EFJ5vyuMWPG6LPPPpPdblenTp3UsmVLbdiwQVu2bHE978iRI/XWW2+5zn3jjTcqOjpab7/9dpnxllUBS05O1rFjxxQTE+OR9yTQFRQUKCMjQ3379nUNIQUAuONaCeDUKalBg1A5HDbt2VOg+HirI6q6JUtsGjYsVJ07O7R2rWd70fvS9TI7O1uNGjXSiRMnzpsbWFYBa9Sokex2uw6f1ZPy8OHDatKkSZmPiY+PV1hYmCv5kqTWrVvr0KFDys/PV3h4uJo3b65PP/1Uubm5ys7OVnx8vEaMGKFmzZq5njc0NFRt2rRxO3fr1q1dwxTLEhERoYiIiFL7w8LCLP8H9ze8ZwBwflwrgeC1bZvkcEiNG0vJyWGy2ayOqOqaNjW/7t0borCwmun/5wvXy8o8v2VdEMPDw9W5c2etWLHCtc/hcGjFihVuFbGSevTooR07dsjhKB4/un37dsXHxys8PNzt2OjoaMXHx+v48eNKT0/XoEGDXM/btWtXbdu2ze347du3KyUlxVMvDwAAAKgSZwfEDh3k18mXVLwY85EjUonBZEHN0jb0aWlpmj17tubOnastW7bo7rvvVm5urqsr4m233ebWpOPuu+9WZmamJkyYoO3bt2vp0qV68sknNW7cONcx6enpWr58uXbt2qWMjAz17t1brVq1cp1Tkh544AHNnz9fs2fP1o4dOzRz5kwtWbJE99xzj/dePAAAAFCGQOmAKEkNGkhRUeb2vn3WxuIrLG1DP2LECB09elSPPPKIDh06pI4dO2r58uWuxhy//PKLQkKKc8Tk5GSlp6fr/vvvV/v27ZWYmKgJEyZo0qRJrmNOnDihyZMna9++fWrQoIGGDRumJ554wq0sOGTIEM2aNUtPPfWU7rvvPl100UV67733dMUVV3jvxQMAAABlcFbAAiEBs9nMKti2bWYrelZ+srAJh7/Lzs5W3bp1KzTRDqaCggItW7ZMAwYMsHycLgD4Kq6VQHBzOKS6daWTJ6XNm6W2ba2OqPr69pU++USaO1e67TbPndeXrpeVyQ0sHYIIAAAAoNjOnWbyFREhXXSR1dF4BosxuyMBAwAAAHyEc/hhu3ZSqKWThTzH2Yhj715r4/AVJGAAAACAj3A24OjQwdIwPIoKmDsSMAAAAMBHBFIHRCcqYO5IwAAAAAAfUXINsEBBBcwdCRgAAADgA379tbhK1L69tbF4kjMBy8mRTpywNhZfQAIGAAAA+ABn9atZM7MVfaCIjjYXZJaogkkkYAAAAIBPCMThh07MAytGAgYAAAD4gEBswOHkHIZIAkYCBgAAAPiEQE7AnBUwhiCSgAEAAACWy8+XtmwxtwNxCCIVsGIkYAAAAIDFfvxRKiiQ6tUrrhYFElrRFyMBAwAAACzmbMDRsaNks1kaSo2gCUcxEjAAAADAYs75X4E4/FByH4LocFgbi9VIwAAAAACLBXIDDklKSJBCQsxhlkeOWB2NtUjAAAAAAAsZhvsQxEAUFibFx5vbwT4PjAQMAAAAsNDevdLx41JoqNS6tdXR1BzmgZlIwAAAAAALOYcftmkjRURYGkqNohOiiQQMAAAAsJBz+GGgNuBwogJmIgEDAAAALBToDTicWIzZRAIGAAAAWCjYEjCGIAIAAACwRHa2tHOnuc0QxOBAAgYAAABY5Pvvza9JSVLDhtbGUtOcFbBDh6T8fGtjsRIJGAAAAGCRYBl+KEmxsWaXR8OQ9u+3OhrrVCkB27t3r/bt2+f6/uuvv9bEiRP1yiuveCwwAAAAINAFSwdESbLZmAcmVTEBu+WWW7Rq1SpJ0qFDh9S3b199/fXXevjhh/Xoo496NEAAAAAgUAVTBUxiHphUxQRs8+bNuvTSSyVJ77zzji6++GJ9+eWX+u9//6s33njDk/EBAAAAAamwUNq82dwOlgSMClgVE7CCggJF/LZM9yeffKIbb7xRktSqVSsdPHjQc9EBAAAAAWr7dunMGal2balZM6uj8Q4qYFVMwNq2batZs2bp888/V0ZGhq699lpJ0oEDB9Qw0Nu3AAAAAB7gHH7Yvr0UEiSt8ViMuYoJ2NNPP61///vfuuqqqzRy5Eh1+G3W4OLFi11DEwEAAACUz9mAI1iGH0rFFbBgHoIYWpUHXXXVVTp27Jiys7NVv3591/677rpLtWrV8lhwAAAAQKByVsCCoQOiExWwKlbATp8+rby8PFfytWfPHs2YMUPbtm1T48aNPRogAAAAEIiCrQOiVJyAZWVJOTmWhmKZKiVggwYN0n/+8x9JUlZWlrp166Z//vOfGjx4sF5++WWPBggAAAAEmkOHpCNHzLlfF19sdTTeU6eOVK+euR2sVbAqJWAbN25Uz549JUkLFixQXFyc9uzZo//85z/617/+5dEAAQAAgEDjrH61bCkF2wyeYG9FX6UE7NSpU6pTp44k6eOPP9bQoUMVEhKiyy67THv27PFogAAAAECgCcbhh07B3oq+SglYixYt9MEHH2jv3r1KT09Xv379JElHjhxRTEyMRwMEAAAAAo2zA2IwNeBwogJWBY888oj+3//7f0pNTdWll16q7t27SzKrYZdccolHAwQAAAACDRWw4K2AVakN/U033aQrrrhCBw8edK0BJknXXHONhgwZ4rHgAAAAgEBz6pS0fbu5HYwJWLBXwKqUgElSkyZN1KRJE+3bt0+SlJSUxCLMAAAAwHls3iw5HFLjxlKTJlZH433BXgGr0hBEh8OhRx99VHXr1lVKSopSUlJUr149PfbYY3I4HJ6OEQAAAAgYwTz8UHJfjNkwrI3FClWqgD388MN67bXX9Pe//109evSQJK1Zs0ZTp07VmTNn9MQTT3g0SAAAACBQOBtwBGsClpgo2WxSXp509KhZCQwmVUrA5s6dq1dffVU33nija1/79u2VmJioe+65hwQMAAAAKIezAhaMHRAlKTzcHHp58KBZBQu2BKxKQxAzMzPVqlWrUvtbtWqlzMzMagcFAAAABCKHgwqYFNyNOKqUgHXo0EEzZ84stX/mzJlq3759tYMCAAAAAtHOnVJurhQZKbVsaXU01gnmRhxVGoL4zDPPaODAgfrkk09ca4CtXbtWe/fu1bJlyzwaIAAAABAonMMPL75YCq1yP3L/RwWsknr16qXt27dryJAhysrKUlZWloYOHaoffvhB8+bN83SMAAAAQEAI9g6ITlTAqiAhIaFUs43vvvtOr732ml555ZVqBwYAAAAEGuZ/maiAAQAAAKhxwd4B0SmYK2AkYAAAAIAX/PqrtG+fuR3sfeucFbCDB6WCAmtj8TYSMAAAAMALnMMPmzWTYmKsjcVqjRub64E5HNKBA1ZH412VmgM2dOjQc96flZVVnVgAAACAgEUDjmIhIVJSktmWf+9eKSXF6oi8p1IJWN26dc97/2233VatgAAAAIBARALmLjnZTMCCrRFHpRKw119/vabiAAAAAAKacwhisDfgcArWRhzMAQMAAABqWF6e9OOP5jYVMFOwtqInAQMAAABq2JYtUmGhVL9+ceIR7KiAAQAAAKgRJdf/stksDcVnUAEDAAAAUCNowFEaFTAAAAAANcLZgIMErJizApaZKeXmWhuLN5GAAQAAADXIMNyHIMJUt27xgtTBVAUjAQMAAABq0C+/SFlZUliY1KaN1dH4FmcVjAQMAAAAgEc4hx+2aSOFh1sbi68JxkYcPpGAvfjii0pNTVVkZKS6deumr7/++pzHZ2Vlady4cYqPj1dERIRatmypZcuWue7PycnRxIkTlZKSoqioKF1++eVav3692zluv/122Ww2t9u1115bI68PAAAAwYvhh+ULxkYcoVYHMH/+fKWlpWnWrFnq1q2bZsyYof79+2vbtm1q3LhxqePz8/PVt29fNW7cWAsWLFBiYqL27NmjevXquY658847tXnzZs2bN08JCQl688031adPH/34449KTEx0HXfttdfq9ddfd30fERFRo68VAAAAwYcOiOULxgqY5QnYs88+q7Fjx+qOO+6QJM2aNUtLly7VnDlz9NBDD5U6fs6cOcrMzNSXX36psLAwSVJqaqrr/tOnT+u9997TokWLdOWVV0qSpk6dqiVLlujll1/W448/7jo2IiJCTZo0qcFXBwAAgGDnHIJIBaw0KmBelp+frw0bNmjy5MmufSEhIerTp4/Wrl1b5mMWL16s7t27a9y4cVq0aJFiY2N1yy23aNKkSbLb7SosLFRRUZEiIyPdHhcVFaU1a9a47Vu9erUaN26s+vXr6+qrr9bjjz+uhg0blvm8eXl5ysvLc32fnZ0tSSooKFBBQUGVXn+wcb5PvF8AUD6ulUBgOXFC2rnTLBq0aVMgfrXdxcfbJIVqzx5DBQWFlXqsL10vKxODpQnYsWPHVFRUpLi4OLf9cXFx2rp1a5mP2blzp1auXKlRo0Zp2bJl2rFjh+655x4VFBRoypQpqlOnjrp3767HHntMrVu3VlxcnN5++22tXbtWLVq0cJ3n2muv1dChQ9W0aVP9/PPP+stf/qLrrrtOa9euld1uL/W8Tz31lKZNm1Zq/8cff6xatWpV850ILhkZGVaHAAA+j2slEBh++KGBpJ5q1OiUvvqK3+uzHTxYS1Jf7dlTpKVLl8lmq/w5fOF6eerUqQofazMMw6jBWM7pwIEDSkxM1Jdffqnu3bu79j/44IP69NNP9dVXX5V6TMuWLXXmzBnt2rXLlSg9++yzmj59ug4ePChJ+vnnnzVmzBh99tlnstvt6tSpk1q2bKkNGzZoy5YtZcayc+dONW/eXJ988omuueaaUveXVQFLTk7WsWPHFONcwADnVFBQoIyMDPXt29c1fBQA4I5rJRBYXnopRBMn2jVggEMffFBkdTg+Jy9PqlPHvNYdOFCgRo0q/lhful5mZ2erUaNGOnHixHlzA0srYI0aNZLdbtfhw4fd9h8+fLjcuVnx8fEKCwtzq1K1bt1ahw4dUn5+vsLDw9W8eXN9+umnys3NVXZ2tuLj4zVixAg1a9as3FiaNWumRo0aaceOHWUmYBEREWU26QgLC7P8H9zf8J4BwPlxrQQCw6ZN5tdOnUIUFuYTDch9SliYFBcnHT4sHToUpvj4qpzD+utlZZ7f0p+C8PBwde7cWStWrHDtczgcWrFihVtFrKQePXpox44dcjgcrn3bt29XfHy8ws9aWCE6Olrx8fE6fvy40tPTNWjQoHJj2bdvn3799VfFV+VfHQAAACiDswEHHRDLF2ydEC1Pw9PS0jR79mzNnTtXW7Zs0d13363c3FxXV8TbbrvNrUnH3XffrczMTE2YMEHbt2/X0qVL9eSTT2rcuHGuY9LT07V8+XLt2rVLGRkZ6t27t1q1auU658mTJ/XAAw9o3bp12r17t1asWKFBgwapRYsW6t+/v3ffAAAAAASkwsLiChgdEMsXbJ0QLW9DP2LECB09elSPPPKIDh06pI4dO2r58uWuxhy//PKLQkKK88Tk5GSlp6fr/vvvV/v27ZWYmKgJEyZo0qRJrmNOnDihyZMna9++fWrQoIGGDRumJ554wlUatNvt+v777zV37lxlZWUpISFB/fr102OPPcZaYAAAAPCIbdvMOU61a0vnmAkT9JwVMBIwLxo/frzGjx9f5n2rV68uta979+5at25duecbPny4hg8fXu79UVFRSk9Pr3ScAAAAQEWVXP8rxPJxZ76LIYgAAAAAqu3bb82vDD88t2AbgkgCBgAAANQAZwJGA45zowIGAAAAoFoMgwSsopwVsAMHzMYlgY4EDAAAAPCwQ4eko0fNuV8XX2x1NL4tLk4KDZWKiqSDB62OpuaRgAEAAAAe5qx+XXSRFBVlaSg+z26XkpLM7WCYB0YCBgAAAHhYyQ6IOL9gmgdGAgYAAAB4GPO/KieYOiGSgAEAAAAeRgJWOcG0GDMJGAAAAOBBubnS9u3mNkMQK4YhiAAAAACqZPNmsw19XJzUpInV0fgHhiACAAAAqBJnAw6GH1YcFTAAAAAAVeKc/8Xww4pzVsCOHZNOn7Y2lppGAgYAAAB4EA04Kq9ePSk62twO9GGIJGAAAACAhzgc0vffm9skYBVnswXPPDASMAAAAMBDfv7Z7IIYGSldeKHV0fiXYJkHRgIGAAAAeIhz+GG7dlJoqKWh+B0qYAAAAAAqhQ6IVUcFDAAAAECl0AGx6qiAAQAAAKgUOiBWnbMCRgIGAAAA4LyOHZP27ze327e3NhZ/VHIIomFYG0tNIgEDAAAAPMA5/6t5c6lOHWtj8UfOBCw3V8rKsjSUGkUCBgAAAHgAww+rJypKatTI3A7kRhwkYAAAAIAHOCtgNOCoumBoxEECBgAAAHgAFbDqC4ZW9CRgAAAAQDXl5UlbtpjbJGBVRwUMAAAAwHn9+KNUWCjVry8lJVkdjf+iAgYAAADgvEoOP7TZrIzEv1EBAwAAAHBezgYcDD+snmBYjJkEDAAAAKgmZwWMDojV40zA9u2TioqsjaWmkIABAAAA1WAYdED0lPh4yW4359MdPmx1NDWDBAwAAACohl9+kU6ckMLCpNatrY7Gv4WGSgkJ5nagNuIgAQMAAACqwVn9atNGCg+3NJSAEOiNOEjAAAAAgGpg+KFnBXorehIwAAAAoBqcHRBpwOEZVMAAAAAAlIsKmGdRAQMAAABQphMnpF27zG0qYJ5BBQwAAABAmb7/3vyanCw1aGBtLIGCChgAAACAMjH80POcFbAjR6S8PGtjqQkkYAAAAEAVORtwkIB5ToMGUlSUub1vn7Wx1AQSMAAAAKCKnBUw5n95js0W2MMQScAAAACAKigslDZvNrepgHlWIDfiIAEDAAAAqmDbNnOOUp06UtOmVkcTWKiAAQAAAHDjHH7Yvr0Uwqdqj6ICBgAAAMANHRBrDhUwAAAAAG7ogFhzqIABAAAAcDEMOiDWJCpgAAAAAFwOHpSOHjXnfl18sdXRBB5nApaTI504YW0snkYCBgAAAFSSc/hhq1bFiwbDc6KjzQWZpcCrgpGAAQAAAJXE8MOa56yCBdo8MBIwAAAAoJLogFjzArURR6jVAQAAAKC0oiLp88/NuUbx8VLPnpLdbnVUcHIOQaQCVnMCtREHCRgAAICPWbhQmjBB2reveF9SkvT889LQodbFBVNurrR9u7lNBazmBGoFjCGIAAAAPmThQummm9yTL0nav9/cv3ChNXGh2ObNZhv6Jk2kuDirowlcgVoBIwEDAADwEUVFZuXLMErf59w3caJ5HKxDAw7vCNQKGEMQAQAAvKSwUDp8WDpwoOzb9u2lK18lGYb5YXTQIOmKK6SmTaVmzcyvDRtKNpv3XkswowGHd5TsguhwmGuuBQISMAAAgGpyOKRjx8pPrJy3w4fNY6tr6VLzVlKdOsUJmTMpc35NTWWtKk9yNuAgAatZCQlm0lVQIB05Yg75DAQkYAAAAOUwDCkr6/yJ1cGD5ofEirDbzQ+SCQnFt8RE8+vRo9KkSec/x223mbHt3Cnt2mXGkJMjff+9eStLfHzpxMz5NTExcKoLNa2oqPg9ZghizQoLM39u9+8354GRgAEAAPixkyfPn1gdOCCdPl3xczZuXHZiVfIWG1t+O/miIumFF8wPnGXNA7PZzG6Ic+a4n+P0aWnPnuKErOTXnTvN5OzgQfP2xRelzxseblbJykrOmjWT6tWr+HsQ6H7+2eyCGBUltWxpdTSB74ILzN+HvXulSy+1OhrPIAEDAAAB5cwZM9EoL6Hav7+4YlRR9eufO6lKSDC74YWHVy92u91sNX/TTWayVTIJc87vmjGjdAIXFSW1amXezmYYUmZm2cnZrl1m4pafb84/c7ZWP1u9eu4JWcntlJTqv25/4hx+2K4d67J5Q3KytHZtYDXiIAEDAAB+oaDg3A0snIlVZmbFzxkdXZxQlZdYxcd7d/7U0KHSggVlrwM2Y0bl1wGz2cwGHQ0bSl27lr6/sNB878qrnh05Yg7D3LjRvJV1/qSk8qtnTZoEVnMQOiB6VyC2oicBAwAAlnI4zLlP50qqDhwwE4GyhuWVJSLi3EmV81anTs2+tqoaOtTsdPj552Y1Lz5e6tmzZiouoaFmFSslRerdu/T9ublmQlZW9WznTunUKbM6sXev9NlnpR8fGVl+cta0qe/+G5SHDojeFYit6H0iAXvxxRc1ffp0HTp0SB06dNALL7ygS88xyDMrK0sPP/ywFi5cqMzMTKWkpGjGjBkaMGCAJCknJ0d/+9vf9P777+vIkSO65JJL9Pzzz6trWX/2kfSnP/1J//73v/Xcc89p4sSJNfESAQAIOoYhHT9+/sTq0CGzClMRoaFmMnKupCohwRwy6O9VF7tduuoqq6Mwq4QXX2zezmYYZvJcXvVs715zSOiWLeatLI0ald+9MTnZbMTgS+iA6F1UwGrA/PnzlZaWplmzZqlbt26aMWOG+vfvr23btqlx48aljs/Pz1ffvn3VuHFjLViwQImJidqzZ4/qlZgdeuedd2rz5s2aN2+eEhIS9Oabb6pPnz768ccflZiY6Ha+999/X+vWrVNCQkJNv1QAAAJGTs65kyrnLS+vYuez2cw5VOdLrGJj6dbnS2w2s/FI48bSZZeVvr+gwPzgXF717Ndfzfb9x45J69eXfrzdbn4AL696Fhvr3UT76FHz51wy54Ch5lEBqwHPPvusxo4dqzvuuEOSNGvWLC1dulRz5szRQw89VOr4OXPmKDMzU19++aXCfvuTSGpqquv+06dP67333tOiRYt05ZVXSpKmTp2qJUuW6OWXX9bjjz/uOnb//v269957lZ6eroEDB9bgqwQA4PyKiqRPP7Xps88SFR1tU+/e3p/kf/p06QYWZSVWJ09W/JwNG54/sYqL871KB6ovLExq3ty8lSU72314Y8nkbPdus3q2e7d5K0t0dPnJWdOmUq1annstRUXSf/5jbickePbcKJ+zAnbokNksJhAavliagOXn52vDhg2aPHmya19ISIj69OmjtWvXlvmYxYsXq3v37ho3bpwWLVqk2NhY3XLLLZo0aZLsdrsKCwtVVFSkyMhIt8dFRUVpzZo1ru8dDoduvfVWPfDAA2rbtm3NvEAAACpo4UJn04VQSV307LNmY4Pnn69804WyFBSYH2DOlVQdOGAOGayomJhzJ1WJiWYDhrP+SwZcYmLMZhZlNbRwOMyf2fKqZ/v3m/PTNm0yb2WJiys7QWvWzPz5rOgfOIp/P83vDxww2/Z76vcT5YuNNed05uWZ/+ZNm1odUfVZmoAdO3ZMRUVFiouLc9sfFxenrVu3lvmYnTt3auXKlRo1apSWLVumHTt26J577lFBQYGmTJmiOnXqqHv37nrsscfUunVrxcXF6e2339batWvVokUL13mefvpphYaG6r777qtQrHl5ecorMY4iOztbklRQUKCCiq68GOSc7xPvFwC4e/99m373O/tvDSaKx1Pt32/oppuk//2vSEOGlN19oqjIHBZ18KC0f79NBw/aflsY2PZbJcv8euRIxcdpRUYaSkyU4uON3+ZbmV/j443fkivz+9q1K3Y+LvuoqthY81ZWa4C8PLOF/u7dNu3aZfutkla8feKETYcPm50zy/q7fliYoZQUKTXVUNOmxm/roBm/Vc8M1zzC6vx+wjOSk0O1Y4dNO3cWKimp+L32pc+WlYnB8iGIleVwONS4cWO98sorstvt6ty5s/bv36/p06drypQpkqR58+ZpzJgxSkxMlN1uV6dOnTRy5Eht2LBBkrRhwwY9//zz2rhxo2wVHDj81FNPadq0aaX2f/zxx6pFDbpSMjIyrA4BAHxGUZF0zz39ZBh2lfxwJ0mGYZNkaOzYIn366Y/KyopUZqZ5O37c+TVCDkfFJkWFhjpUv/4ZNWhwxvXVeWvY0Ln/tKKjC8udV5ObK/30k3kDfEVysnn7bfaJJOnkyTAdPlzrt1u02/aRI7VUUBCiHTukHTvK/mGvVatAjRvn6sCBOqWSL6n493PcuHyFhmawJlgNioq6XFKsPvzwO508ua/U/b7w2fLUqVMVPtbSBKxRo0ay2+06fPiw2/7Dhw+rSZMmZT4mPj5eYWFhspf4KW/durUOHTqk/Px8hYeHq3nz5vr000+Vm5ur7OxsxcfHa8SIEWrWrJkk6fPPP9eRI0d0gXNWn6SioiL9+c9/1owZM7S7jIHGkydPVlpamuv77OxsJScnq1+/foqJianO2xA0CgoKlJGRob59+7rm7wFAsPv0U5t+/fVc/x3blJ0doZdeuqTcI0JCDMXFla5YJSQYv61jZX5t2FAKCQmTFCbJz3p/Ax5UVFSkAweKfqueSTt32lzbu3ebleRTp8K0e3e985zJpmPHaikmZqB69aIKVlPee8+uTZukBg06asCA9q79vvTZ0jk6riIsTcDCw8PVuXNnrVixQoMHD5ZkVrhWrFih8ePHl/mYHj166K233pLD4VDIb22Qtm/frvj4eIWfNSsvOjpa0dHROn78uNLT0/XMM89Ikm699Vb16dPH7dj+/fvr1ltvdTUDOVtERIQiIiJK7Q8LC7P8H9zf8J4BgOnAAenttyt2bPv2UpcuZa9t1bixTaGh0tl/oQdQtrCw4rlgZTl92mz88frr0vTp5z/f0aOhNJGpQSkp5tcDB+wKCytdavSFz5aVeX7LhyCmpaVp9OjR6tKliy699FLNmDFDubm5rkTotttuU2Jiop566ilJ0t13362ZM2dqwoQJuvfee/XTTz/pySefdJvLlZ6eLsMwdNFFF2nHjh164IEH1KpVK9c5GzZsqIYNG7rFERYWpiZNmuiiiy7y0isHAASjrVulDz4wb199VfHHPf+8b6wJBQSDqCipdWtpwICKJWDx8TUfUzALtFb0lidgI0aM0NGjR/XII4/o0KFD6tixo5YvX+5qzPHLL7+4Kl2SlJycrPT0dN1///1q3769EhMTNWHCBE2aNMl1zIkTJzR58mTt27dPDRo00LBhw/TEE09YnhkDAIKPwyF9/XVx0rVtm/v93bqZSVl2tn6bZ+LOZjO7Ifbs6Y1oAZTUs6f5+7d/P7+fVgq0xZhthlHWjxPOJzs7W3Xr1tWJEyeYA1ZBBQUFWrZsmQYMGEAyDCCg5edLK1eaCdeiRWYrbaewMOmaa6TBg6UbbzT/cr5woXTTTeb9Jf9XdjbCWLCAVteAVfj9tN6PP0pt20r16rkvleFLny0rkxtYXgEDACAQZGdLH31kJl3LlpnfO9WpIw0caCZd111nrn1U0tCh5oe4kusMSeZf1mfM4MMdYCV+P63nrIBlZUk5OeY11Z+RgAEAUEUHD0qLF5tJ14oV7utdxcdLgwaZSddVV5kLiZ7L0KHm8atWFeqjj77Vddd1VO/eobS2BnyA8/fz88/N3/v4eHPYIb+f3lGnjln9ysoy54G1aWN1RNVDAgYAQCVs21Y8n2vdOvf7WrUyE67Bg6WuXaWQii3P5WK3S716GcrN3a9evTrw4Q7wIXY7jXCslJxsJmC//EICBgBAQHM4pPXri5OurVvd7+/WTRoyxPzreKtWVkQIAIHvggukTZsCoxMiCRgAICgUFVV8+FB+vrRqVXETjYMHi+8LC5Ouvrq4iUZCgjeiB4DgFkidEEnAAAABb+HCsifQP/988QT68zXRGDCguIlG3brejB4AEEhrgZGAAQACmrOF9NmLruzfb+6/6y5pz57STTSaNCluotG79/mbaAAAao6zAkYCBgCADysqMitfZa146dz3738X72vZ0pzPNXiwdOmllW+iAQCoGQxBBADAD3z+ufuww/KMHSulpdFEAwB8VckhiIZRvBC2P+JvewCAgFWyeca59O5N8gUAviwx0Uy68vKko0etjqZ6SMAAAAErPt6zxwEArBEebs7Nlfx/HhgJGAAgYPXsKdWuXf79Nps5r6BnT+/FBAComkCZB0YCBgAIWK+8Ip08WfZ9zvkDM2aUvx4YAMB3BEorehIwAEBAWr5cuvdec3vkSHPdr5KSkqQFC4rXAQMA+LZAqYDRBREAEHA2b5aGDzfb0I8eLb3+uuRwmF0RDx4053z17EnlCwD8SaBUwEjAAAAB5dAhaeBAKSdH6tXLHIZos5nJ1lVXWR0dAKCqAqUCxhBEAEDAOHVKGjTI/M/5wgul994zO2cBAPyfMwHz9woYCRgAICA4HNJtt0lffy01aCAtXSo1bGh1VAAAT3EOQTx4UCoosDaW6iABAwAEhIcfNiteYWHS+++bFTAAQOBo3Ni8xjsc0oEDVkdTdSRgAAC/N2eO9Pe/m9uvvipdeaW18QAAPC8kJDCGIZKAAQD82sqV0h//aG7/7W/mMEQAQGAKhEYcJGAAAL+1das0bJhUWCj97nfStGlWRwQAqEmB0IqeBAwA4JeOHjXbzWdlSd27m2t92WxWRwUAqElUwAAAsMCZM9KQIdLOnVLTptKiRVJkpNVRAQBqGhUwAAC8zDCkP/xB+uILqW5ds918bKzVUQEAvIEKGAAAXjZtmvTWW1JoqNl2vnVrqyMCAHgLFTAAALzov/8tbrTx8svSNddYGw8AwLucFbDMTCk319pYqooEDADgFz7/XBozxtx+8EHpzjutjQcA4H1160p16pjb/loFIwEDAPi8HTvMphv5+dLQodJTT1kdEQDAKs5hiPv2+WfrWxIwAIBPO37cbDf/669Sly7SvHlSCP97AUDQcg5DpAIGAICHOSte27eb/+EuXizVqmV1VAAAKxU34qACBgCAxxiG9Kc/SatXm+P9P/xQio+3OioAgNWKK2AkYAAAeMzTT0uvv24ON5w/X2rf3uqIAAC+oHgOmLVxVBUJGADA57z7rjR5srn9r39J111nbTwAAN9RvBgzFTAAAKrtq6+k224zt++7Txo3ztp4AAC+pWQFzDCsjaUqSMAAAD5j927pxhulM2fMzofPPmt1RAAAX5OUZH49fdqmnJxwa4OpAhIwAIBPOHFCuv566cgRqUMH6e23Jbvd6qgAAL4mIkJq3NjcPnYsytpgqoAEDABgucJCafhw6YcfzE6HH35odj4EAKAsznlgn36apE8/tamoyNp4KoMEzM8VFZktmt9+2/zqTz98ACCZ4/fvvVf6+GNzja8lS4qHlwAAcLaFC80/2EnSokUt1LdvqFJTzf3+gATMjy1cKKWmSr17S7fcYn71px8+AJCkGTOkWbMkm0166y2pc2erIwIA+KqFC6WbbjLnCpe0f7+53x8+B5OA+SnnD9/Z6x/40w8fACxaJP35z+b2P/4hDRpkbTwAAN9VVCRNmFB250PnvokTfX9EGAmYHwqUHz4AwW3jRrN6bxjSH/8o3X+/1REBAHzZ55+fe/Flw5D27jWP82UkYH4oUH74AASvffukG26QTp2S+vWTXnjBHIIIAEB5Dh707HFWIQHzQ4HywwcgOJ08aSZfBw5IbdpI77wjhYVZHRUAwNfFx3v2OKuQgPmhQPnhAxB8ioqkkSOlb78113BZulSqW9fqqAAA/qBnT7NLbnkjJmw2sz19z57ejauySMD8UKD88AEIPn/+s7nGV2Sk2YAjNdXqiAAA/sJul55/3tw++3Ow8/sZM8zjfBkJmB861w+fZM4Be+453//hAxBcXnyx+Nr1n/9Il11mbTwAAP8zdKi0YIGUmOi+PynJ3D90qDVxVQYJmJ8q74fPKSvLq+EAwDktXy7dd5+5/eST0s03WxsPAMB/DR0q7d4tZWQUKi3tG2VkFGrXLv9IviQSML/m/OFbtcpcvHTVKunvfzfvmzBB+uknS8MDAEnSpk3S8OGSwyHdfrv00ENWRwQA8Hd2u9Srl6Err9yvXr0Mvxr5FWp1AKgeu1266qri73v2NP/SvHq19PvfS2vW0F0MgHUOHZIGDpRycsxr1b//Tbt5AEBwowIWYOx2c25FvXrS119Ljz9udUQAgtWpU9KNN5rrErZsKb33nhQebnVUAABYiwQsACUnS7NmmduPPy59+aW18QAIPg6HdOut0vr1UoMGZrv5Bg2sjgoAAOuRgAWoESPMDz8OhzkUMTvb6ogABJO//EVauNCseH3wgdSihdURAQDgG0jAAtgLL0gpKdKuXWZTDgDwhldflZ5+2tx+7TXWJAQAoCQSsABWt6705ptSSIj0xhtm23oAqEkrVkh3321uP/KIWYEHAADFSMAC3BVXSJMnm9t33SXt22dtPAAC15Yt0rBhUmGhNHKkNHWq1REBAOB7SMCCwJQpUpcu0vHj5ho8DofVEQEINEePmu3mT5yQLr9cmjOHdvMAAJSFBCwIhIVJ//2vVKuWOTxoxgyrIwIQSM6ckQYPNuebNmtmNt2IjLQ6KgAAfBMJWJBo2VJ67jlze/Jk6bvvrI0Hwa2oyFws/O23za9FRVZHhKoyDGnMGHO5i7p1zXbzsbFWRwUAgO8iAQsiY8eai6Lm50ujRkmnT1sdEYLRwoVSaqrUu7d0yy3m19RUcz/8z9SpZiIdGmr+G7ZqZXVEAAD4NhKwIGKzme2h4+KkH36QHnrI6ogQbBYulG66qXQzmP37zf0kYf5l3jzp0UfN7VmzpKuvtjYeAAD8gU8kYC+++KJSU1MVGRmpbt266euvvz7n8VlZWRo3bpzi4+MVERGhli1batmyZa77c3JyNHHiRKWkpCgqKkqXX3651q9f73aOqVOnqlWrVoqOjlb9+vXVp08fffXVVzXy+nxJbKz0+uvm9r/+JaWnWxsPgkdRkbkenWGUvs+5b+JEhiP6i88+k/7wB3N70qTibQAAcG6WJ2Dz589XWlqapkyZoo0bN6pDhw7q37+/jhw5Uubx+fn56tu3r3bv3q0FCxZo27Ztmj17thITE13H3HnnncrIyNC8efO0adMm9evXT3369NH+/ftdx7Rs2VIzZ87Upk2btGbNGqWmpqpfv346evRojb9mq113nTR+vLl9++3SsWOWhoMgYBjmmnTnWgbBMKS9e83lEhYskL7/Xjp1ynsxouJ27JCGDJEKCsy2808+aXVEAAD4D5thlPX3aO/p1q2bunbtqpkzZ0qSHA6HkpOTde+99+qhMsbIzZo1S9OnT9fWrVsVFhZW6v7Tp0+rTp06WrRokQYOHOja37lzZ1133XV6/PHHy4wjOztbdevW1SeffKJrrrnmvHE7jz9x4oRiYmIq+nJ9xunTUufO5ro9gwebQ79qumV0QUGBli1bpgEDBpT5b4fAkp9vVkk+/FBaskTaubNq50lONpvIXHSR+dV5S0kx5x3BuzIzpe7dpe3bpa5dzSYqtWpZHVVg4VoJABXjS9fLyuQGln58yc/P14YNGzTZuVKwpJCQEPXp00dr164t8zGLFy9W9+7dNW7cOC1atEixsbG65ZZbNGnSJNntdhUWFqqoqEiRZ/VAjoqK0po1a8qN45VXXlHdunXVoUMHz71AHxYVJb31lnTppWbL6Ndek+680+qo4O+OHpU++shMuNLTpZyc4vtCQ80Fes+nXz8pO1vats1cu27vXvO2YoX7cWFhUosW7kmZM1Fr3Jg1qGpCfr40dKiZfF1wgbR4MckXAACVZWkCduzYMRUVFSkuLs5tf1xcnLZu3VrmY3bu3KmVK1dq1KhRWrZsmXbs2KF77rlHBQUFmjJliurUqaPu3bvrscceU+vWrRUXF6e3335ba9euVYsWLdzO9eGHH+p3v/udTp06pfj4eGVkZKhRo0ZlPm9eXp7y8vJc32dnZ0syM++CgoLqvA2WadtWevTREE2ebNeECYYuv7xQF15Yc8/nfJ/89f1CaYZhNnRZujREy5bZtG6dTYZRnPnExRm67jpDAwc6dNVVhjp2DNWBA3I7xslmM5SYKC1aVCi73dz366/STz/ZtH27tH27TT/9ZN527JDOnLFpyxazinu2mBhDF15o6MILpZYtze2WLQ21aCHVqVNT70ZgMwzpzjvt+vTTENWpY+j99wvVsKE5DBGexbUSACrGl66XlYnB0iGIBw4cUGJior788kt1797dtf/BBx/Up59+WmZTjJYtW+rMmTPatWuX7L99Snv22Wc1ffp0HTx4UJL0888/a8yYMfrss89kt9vVqVMntWzZUhs2bNCWEp/WcnNzdfDgQR07dkyzZ8/WypUr9dVXX6lx48alnnfq1KmaNm1aqf1vvfWWavnxn4AdDmnKlMu1aVOsLrzwuJ566nOFhlo6KhU+rqAgRJs3N9T69U30zTdxOnIk2u3+Zs2y1KXLYXXpckgtWmQppMRM07Vr4/X0011/+65kEmb+zE2atF7dux88bwwOh3TsWJQOHKj92y1aBw7U1v79tXXkSK0yEzyn+vXPKDExRwkJuUpIOKmEhJNKTMxVXFwuP/vn8O67F+q//22jkBBDf/3rOnXqVPY8XQAAgtGpU6d0yy23VGgIoqUJWH5+vmrVqqUFCxZo8ODBrv2jR49WVlaWFi1aVOoxvXr1UlhYmD755BPXvo8++kgDBgxQXl6ewsPDXftzc3OVnZ2t+Ph4jRgxQidPntTSpUvLjefCCy/UmDFj3IZEOpVVAUtOTtaxY8f8cg5YSXv3Sp07hyory6a//KVIU6c6auR5CgoKlJGRob59+1o+TheVc/iw9NFHNi1dGqJPPrEpN7c4wYmMNHT11YYGDjR03XUOJSWd+1zvv29TWppd+/cXnyMpydA//1mkIUOqfzk6c8acb+aslpmVM/P7I0fKT8zsdkNNmxZXzEpWzxISgntI47vv2jRqlDlg4l//KtKf/lQz1wiYuFYCQMX40vUyOztbjRo18v05YOHh4ercubNWrFjhSsAcDodWrFih8c42fWfp0aOH3nrrLTkcDoX89qf17du3Kz4+3i35kqTo6GhFR0fr+PHjSk9P1zPPPHPOeBwOh1uSVVJERIQiIiJK7Q8LC7P8H7y6mjUz1/D53e+kv//drgED7OrRo+aeLxDes0BnGGYXwiVLzNvZK0PEx0vXXy/dcIN0zTU21arlzE7s5z338OFm57zPP5cOHjTP1bOnTXa7Zy5HYWFShw7m7WxZWdJPP5nzy8xhjcW33FxzaOOOHaUzreho/ZaQlW4GUq+eR8L2WevWSWPGmNsTJ0r33mtXRf6dUX1cKwGgYnzhelmZ57e8h1haWppGjx6tLl266NJLL9WMGTOUm5urO+64Q5J02223KTExUU899ZQk6e6779bMmTM1YcIE3Xvvvfrpp5/05JNP6r777nOdMz09XYZh6KKLLtKOHTv0wAMPqFWrVq5z5ubm6oknntCNN96o+Ph4HTt2TC+++KL279+vm2++2ftvgg8YMUJautRcWPXWW6Vvv5X8vLCHSjpzRlq50uxa+OGHZmW0pC5dzKTr+uulTp2qVxGy26WrrqpWuFVSr57Zua9rV/f9hiEdOOCekDmTtJ07pdxc83fi229Ln7Nx47IbgTRvLpXxNxu/smuXdOONUl6emWz/4x9WRwQAgP+zPAEbMWKEjh49qkceeUSHDh1Sx44dtXz5cldjjl9++cVV6ZKk5ORkpaen6/7771f79u2VmJioCRMmaNKkSa5jTpw4ocmTJ2vfvn1q0KCBhg0bpieeeMKVmdrtdm3dulVz587VsWPH1LBhQ3Xt2lWff/652rZt6903wIfMnGlWJXbtku67T3rjDasjQk07eLA44frkE/d1t6KipL59zQ/eAwZICQnWxVnTbDYpMdG89e7tfl9Bgfk7UTIpc94OHJCOHDFvZzdZDQkxW+WXTMqc28nJcpsb54uyssxk++hRqWNHs2uqncIXAADVZvk6YP7K39cBK8+aNVKvXmaTg3fekTxZEPSltRqClWFIGzcWr821YYP7/UlJxUMLe/c2kzCULyfHHNJ49nDGbdvMVvrliYwsHtJ4duWsYUPvxV+eggJp4EApI8NMvL/6Sued2wfP4VoJABXjS9dLv1kHDL7niiukyZOlJ56Q/vhHc8FVPnj5t1OnzDW0liwxh5keOFB8n81mrgXnHFrYoUNwN5uorDp1zOGYnTq57zcMsyp29nDG7dv1Wwt9adMm83a2Bg1KJ2UtW5prnnmj4aphSPfeayZftWqZPzdcAwAA8BwSMJQyZYr08cfS+vXS6NHmBzFfHy4Fd/v2mcnWkiVm8nXmTPF90dHmYsfOoYVnLcMHD7DZzPc1Lk7q2dP9vsJC6Zdfym4E8ssvUmam2fhi3brS501OLt0EpGVLKTW16sMDi4rcG6KsXy/9+9/ma3j77dLJJQAAqB4SMJQSFia9+aZ0ySVmU4bnnpP+/Gero8K5OBzSN98UDy08u1lESoqZcF1/vdn8wt+bQ/iz0FCz82izZtJ117nfd+qUWSE7u3K2bZt0/LjZGGXvXnO+Xknh4WbTj7IqZ40bl1/VXLhQmjDBTNjP9s9/mg04AACAZ5GAoUwtW0ozZkh33SX95S9Snz5lt/WGdU6eND+IO4cWHj5cfJ/NZg4fdc7natuWoYX+oFYtqX1783a2X38tuxHITz+ZFc4tW8zb2WJiym4EsmWL2fG0vFnAF1zg2dcGAABMJGAo1513mh/sFy2SbrnFrLDQlMFae/YUdy1ctcpsD+5Up47Uv7+ZcF13nRQba12c8LyGDc2kunt39/0Oh1kVK6uF/u7dZjOQb74xbxVls0n33y8NHkznQwAAPI0EDOWy2aTZs80OaD/+KD30kPT881ZHFVyKisxFkJ1DC89u2tCsWfHQwiuvNIeiIbg4292npJjLBpR05oy5jtnZidnmzWab+fIYhpnUff65Neu1AQAQyEjAcE6xsdLrr5sVlX/9y2za0L+/1VEFtuxss/HJkiXSsmXmOkxOISFSjx7FQwtbtWJoIcoXGSm1aWPeSnr7bbOqfT4HD9ZMXAAABDMSMJzXtdeabalfeEG6/Xbp++8Z3uZpu3aZCdeHH0qrV5vrMDnVrWv+G9xwg/nVF9aJgn+Lj/fscQAAoOJIwFAhTz9ttjP/8Udp7Fjp/fepvFRHUZG0dm3x0MIff3S//8ILi4cWXnGF2ZkS8JSePc21vfbvL7sJh81m3n92C30AAFB9JGCokKgo6b//NRftXbRIeu01s0kHKu7ECSk93Uy4PvrI7GrnZLebH3adQwtbtrQuTgQ+u92cz3nTTWayVTIJc/5hZcYMGnAAAFATSMBQYR07Sk8+KT3wgLl2UK9eZqUG5duxo3ho4WefmYvwOtWvb86tu+EGc15d/frWxYngM3SotGBB6XXAkpLM5GvoUMtCAwAgoJGAoVLS0szGEKtWSaNGSV98wfC4kgoLzffEObRw2zb3+1u1Kh5aePnl5qK8gFWGDpUGDTK7HR48aM756tmTyhcAADWJj3+olJAQae5cc6HY9eulRx+VHnvM6qisdfy4tHx58dDCku29Q0PNSuH115u3Fi0sCxMok91Oq3kAALyJBAyVlpws/fvf0ogR5pDEa681W6MHC8Mw11JyDi1cs8ZsquHUsKHZrv+GG6R+/cwuhgAAAIBEAoYqGj5cWrpU+s9/pN//XvruOykmxuqoak5BgTlMyzm0cMcO9/vbti0eWnjZZQzhAgAAQNlIwFBlL7xgNpbYvdtcJ2zuXKsj8qxffzWHFC5ZYg4xzM4uvi8sTOrdu3hoYdOm1sUJAAAA/0EChiqLiZHefFO68kqzEjZwoFkZ81eGIW3ZUjy08MsvJYej+P7YWPM13nCD1LevVKeOdbECAADAP5GAoVp69JD+8hfp8celP/7R7OyXlGR1VBWXny99+mnx0MJdu9zvb9++eGjhpZeaTUgAAACAqiIBQ7U98oj08cfS119Lo0dLGRm+nagcOVI8tPDjj6WcnOL7IiKkq68uHlp4wQXWxQkAAIDAQwKGagsLM4ciduworVwpPfus9P/+n9VRFTMMadMms8r14YfSunXmPqcmTYqHFl5zjVS7tnWxAgAAILCRgMEjLrxQmjFDuusuc0hinz5mQmaVM2ek1auL53P98ov7/ZdcUjy0sHNn367YAQAAIHCQgMFj7rzTbE2/aJE0apT0zTdSVJT3nv/QIWnZMjPpysiQcnOL74uMNJNC59DCxETvxQUAAAA4kYDBY2w26dVXpa++kn78UZo0SfrXv2ru+QxD+vbb4qGFX3/tfn9Cgpls3XCDOa+rVq2aiwUAAACoCBIweFSjRtIbb0jXXmuuEzZggLntKadPm/PMnEML9+93v79Ll+KhhZdcYiaFAAAAgK8gAYPH9e9vLsz8wgvS7bebDTBiY6t+vgMHiqtcn3xiJmFOtWqZa3Jdf73ZSCM+vtrhAwAAADWGBAw14umnzUrVDz9IY8dKCxZIn35q02efJSo62qbevSW7vezHOhzSxo3FSdeGDe73JycXDy286irvzjMDAAAAqoMEDDUiKkr673/NxYsXLZIaN5aOHw+V1EXPPmsu1vz889LQoebxubnSihXm0MKlS6WDB4vPZbOZ53EOLWzfnqGFAAAA8E8kYKgxHTpII0dKc+dKx4+737d/v3TTTWbnxP37zWrZmTPF99euLfXrZyZcAwZIcXHejR0AAACoCSRgqDFFRWZVqyzOhZBnzy7el5JiVrluuEHq1UuKiKj5GAEAAABvIgFDjfn8c2nfvvMfN3asdN99Utu2DC0EAABAYCMBQ40pOY/rXHr3li6+uGZjAQAAAHxBiNUBIHBVtCU8reMBAAAQLEjAUGN69jS7HZY3rNBmM1vK9+zp3bgAAAAAq5CAocbY7Wareal0Eub8fsaM8tcDAwAAAAINCRhq1NCh5iLMiYnu+5OSzP3OdcAAAACAYEATDtS4oUOlQYOkVasK9dFH3+q66zqqd+9QKl8AAAAIOiRg8Aq7XerVy1Bu7n716tWB5AsAAABBiSGIAAAAAOAlJGAAAAAA4CUkYAAAAADgJSRgAAAAAOAlJGAAAAAA4CUkYAAAAADgJSRgAAAAAOAlJGAAAAAA4CUkYAAAAADgJSRgAAAAAOAlJGAAAAAA4CUkYAAAAADgJSRgAAAAAOAloVYH4K8Mw5AkZWdnWxyJ/ygoKNCpU6eUnZ2tsLAwq8MBAJ/EtRIAKsaXrpfOnMCZI5wLCVgV5eTkSJKSk5MtjgQAAACAL8jJyVHdunXPeYzNqEiahlIcDocOHDigOnXqyGazqWvXrlq/fr3Hn8fT5/XE+ap6juzsbCUnJ2vv3r2KiYmpVgyovpr6mfVF/vBarY7Rm8/vD9dLrpUoyerfT2/xl9dpdZzeen5/uFZ66nyBcL00DEM5OTlKSEhQSMi5Z3lRAauikJAQJSUlub632+018g/v6fN64nzVPUdMTIzlvySouZ9ZX+QPr9XqGL35/P5wveRaiZKs/v30Fn95nVbH6a3n94drpafOFyjXy/NVvpxowuEh48aN84vzeuJ8NfVa4V3B9O/oD6/V6hi9+fz+cL3kWomSguXf0l9ep9Vxeuv5/eFa6anzWf1v6m0MQYTXZGdnq27dujpx4oRP/JUCAHwR10oAqBh/vV5SAYPXREREaMqUKYqIiLA6FADwWVwrAaBi/PV6SQUMAAAAALyEChgAAAAAeAkJGAAAAAB4CQkYAAAAAHgJCRgAAAAAeAkJGAAAAAB4CQkYfE5WVpa6dOmijh076uKLL9bs2bOtDgkAfNLevXt11VVXqU2bNmrfvr3effddq0MCAJ80ZMgQ1a9fXzfddJPVodCGHr6nqKhIeXl5qlWrlnJzc3XxxRfrm2++UcOGDa0ODQB8ysGDB3X48GF17NhRhw4dUufOnbV9+3ZFR0dbHRoA+JTVq1crJydHc+fO1YIFCyyNhQoYfI7dbletWrUkSXl5eTIMQ/ydAABKi4+PV8eOHSVJTZo0UaNGjZSZmWltUADgg6666irVqVPH6jAkkYChCj777DPdcMMNSkhIkM1m0wcffFDqmBdffFGpqamKjIxUt27d9PXXX1fqObKystShQwclJSXpgQceUKNGjTwUPQB4jzeul04bNmxQUVGRkpOTqxk1AHiXN6+VvoAEDJWWm5urDh066MUXXyzz/vnz5ystLU1TpkzRxo0b1aFDB/Xv319HjhxxHeOc33X27cCBA5KkevXq6bvvvtOuXbv01ltv6fDhw155bQDgSd64XkpSZmambrvtNr3yyis1/poAwNO8da30FcwBQ7XYbDa9//77Gjx4sGtft27d1LVrV82cOVOS5HA4lJycrHvvvVcPPfRQpZ/jnnvu0dVXX+0TkyYBoKpq6nqZl5envn37auzYsbr11ltrInQA8Jqa/Gy5evVqzZw5kzlgCCz5+fnasGGD+vTp49oXEhKiPn36aO3atRU6x+HDh5WTkyNJOnHihD777DNddNFFNRIvAFjFE9dLwzB0++236+qrryb5AhCQPHGt9DUkYPCoY8eOqaioSHFxcW774+LidOjQoQqdY8+ePerZs6c6dOignj176t5771W7du1qIlwAsIwnrpdffPGF5s+frw8++EAdO3ZUx44dtWnTppoIFwAs4YlrpST16dNHN998s5YtW6akpCRLk7dQy54ZKMell16qb7/91uowAMDnXXHFFXI4HFaHAQA+75NPPrE6BBcqYPCoRo0ayW63l2qacfjwYTVp0sSiqADA93C9BIDzC8RrJQkYPCo8PFydO3fWihUrXPscDodWrFih7t27WxgZAPgWrpcAcH6BeK1kCCIq7eTJk9qxY4fr+127dunbb79VgwYNdMEFFygtLU2jR49Wly5ddOmll2rGjBnKzc3VHXfcYWHUAOB9XC8B4PyC7VpJG3pU2urVq9W7d+9S+0ePHq033nhDkjRz5kxNnz5dhw4dUseOHfWvf/1L3bp183KkAGAtrpcAcH7Bdq0kAQMAAAAAL2EOGAAAAAB4CQkYAAAAAHgJCRgAAAAAeAkJGAAAAAB4CQkYAAAAAHgJCRgAAAAAeAkJGAAAAAB4CQkYAAAAAHgJCRgAAOeQmpqqGTNmWB0GACBAkIABACx3++23a/DgwVaHUab169frrrvuqvHnSU1Nlc1mk81mU61atdSuXTu9+uqrlT6PzWbTBx984PkAAQAeQQIGAAhKBQUFFTouNjZWtWrVquFoTI8++qgOHjyozZs36/e//73Gjh2rjz76yCvPDQDwDhIwAIDP27x5s6677jrVrl1bcXFxuvXWW3Xs2DHX/cuXL9cVV1yhevXqqWHDhrr++uv1888/u+7fvXu3bDab5s+fr169eikyMlL//e9/XZW3f/zjH4qPj1fDhg01btw4t+Ts7CGINptNr776qoYMGaJatWrpwgsv1OLFi93iXbx4sS688EJFRkaqd+/emjt3rmw2m7Kyss75OuvUqaMmTZqoWbNmmjRpkho0aKCMjAzX/evXr1ffvn3VqFEj1a1bV7169dLGjRvdYpWkIUOGyGazub6XpEWLFqlTp06KjIxUs2bNNG3aNBUWFlbk7QcAeBAJGADAp2VlZenqq6/WJZdcom+++UbLly/X4cOHNXz4cNcxubm5SktL0zfffKMVK1YoJCREQ4YMkcPhcDvXQw89pAkTJmjLli3q37+/JGnVqlX6+eeftWrVKs2dO1dvvPGG3njjjXPGNG3aNA0fPlzff/+9BgwYoFGjRikzM1OStGvXLt10000aPHiwvvvuO/3xj3/Uww8/XKnX7HA49N577+n48eMKDw937c/JydHo0aO1Zs0arVu3ThdeeKEGDBignJwcSWaCJkmvv/66Dh486Pr+888/12233aYJEyboxx9/1L///W+98cYbeuKJJyoVFwDAAwwAACw2evRoY9CgQWXe99hjjxn9+vVz27d3715DkrFt27YyH3P06FFDkrFp0ybDMAxj165dhiRjxowZpZ43JSXFKCwsdO27+eabjREjRri+T0lJMZ577jnX95KMv/71r67vT548aUgyPvroI8MwDGPSpEnGxRdf7PY8Dz/8sCHJOH78eNlvwG/PEx4ebkRHRxuhoaGGJKNBgwbGTz/9VO5jioqKjDp16hhLlixxi+/99993O+6aa64xnnzySbd98+bNM+Lj48s9NwCgZlABAwD4tO+++06rVq1S7dq1XbdWrVpJkmuY4U8//aSRI0eqWbNmiomJcQ29++WXX9zO1aVLl1Lnb9u2rex2u+v7+Ph4HTly5JwxtW/f3rUdHR2tmJgY12O2bdumrl27uh1/6aWXVui1PvDAA/r222+1cuVKdevWTc8995xatGjhuv/w4cMaO3asLrzwQtWtW1cxMTE6efJkqdd5tu+++06PPvqo23s4duxYHTx4UKdOnapQbAAAzwi1OgAAAM7l5MmTuuGGG/T000+Xui8+Pl6SdMMNNyglJUWzZ89WQkKCHA6HLr74YuXn57sdHx0dXeocYWFhbt/bbLZSQxc98ZiKaNSokVq0aKEWLVro3XffVbt27dSlSxe1adNGkjR69Gj9+uuvev7555WSkqKIiAh179691Os828mTJzVt2jQNHTq01H2RkZHVjhsAUHEkYAAAn9apUye99957Sk1NVWho6f+2fv31V23btk2zZ89Wz549JUlr1qzxdpguF110kZYtW+a2zzkXqzKSk5M1YsQITZ48WYsWLZIkffHFF3rppZc0YMAASdLevXvdmpFIZnJYVFTktq9Tp07atm2bWzUNAGANhiACAHzCiRMn9O2337rd9u7dq3HjxikzM1MjR47U+vXr9fPPPys9PV133HGHioqKVL9+fTVs2FCvvPKKduzYoZUrVyotLc2y1/HHP/5RW7du1aRJk7R9+3a98847rqYeNputUueaMGGClixZom+++UaSdOGFF2revHnasmWLvvrqK40aNUpRUVFuj0lNTdWKFSt06NAhHT9+XJL0yCOP6D//+Y+mTZumH374QVu2bNH//vc//fWvf63+CwYAVAoJGADAJ6xevVqXXHKJ223atGlKSEjQF198oaKiIvXr10/t2rXTxIkTVa9ePYWEhCgkJET/+9//tGHDBl188cW6//77NX36dMteR9OmTbVgwQItXLhQ7du318svv+zqghgREVGpc7Vp00b9+vXTI488Ikl67bXXdPz4cXXq1Em33nqr7rvvPjVu3NjtMf/85z+VkZGh5ORkXXLJJZKk/v3768MPP9THH3+srl276rLLLtNzzz2nlJQUD7xiAEBl2AzDMKwOAgCAQPbEE09o1qxZ2rt3r9WhAAAsxhwwAAA87KWXXlLXrl3VsGFDffHFF5o+fbrGjx9vdVgAAB9AAgYAgIf99NNPevzxx5WZmakLLrhAf/7znzV58mSrwwIA+ACGIAIAAACAl9CEAwAAAAC8hAQMAAAAALyEBAwAAAAAvIQEDAAAAAC8hAQMAAAAALyEBAwAAAAAvIQEDAAAAAC8hAQMAAAAALyEBAwAAAAAvOT/A8GEfc4F4TYKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import itertools\n",
    "\n",
    "# Zielvariablen für die Vorhersage erstellen\n",
    "data['Target'] = (data['Close'] <= data['Previous_Close']).astype(int)\n",
    "\n",
    "data_clean = data\n",
    "data_clean.dropna(inplace=True)\n",
    "data_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Auswahl und Skalierung der relevanten Features\n",
    "selected_features = ['Close', 'RSI', 'EMA20', 'Bollinger_Middle', 'MACD', 'Previous_Close']\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = sc.fit_transform(data[selected_features])\n",
    "\n",
    "def create_sequences(features, target, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequence = features[i:i + seq_length]\n",
    "        label = target[i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Hyperparameter-Definition\n",
    "learning_rates = [0.1, 0.075, 0.05, 0.025, 0.01, 0.0075, 0.005, 0.0025, 0.001, 0.00075]\n",
    "SEQ_LENGTH = 30  # Konstante Sequenzlänge\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seq_length\": SEQ_LENGTH\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Daten vorbereiten basierend auf der aktuellen seq_length\n",
    "        X, y = create_sequences(scaled_features, data['Target'].values, SEQ_LENGTH)\n",
    "\n",
    "        # Datenaufteilung: 70% Training, 20% Validierung, 10% Test\n",
    "        train_size = int(0.7 * len(X))\n",
    "        val_size = int(0.2 * len(X))\n",
    "        test_size = len(X) - train_size - val_size\n",
    "\n",
    "        X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "        y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "        # Überprüfen der Formen der Daten\n",
    "        print(f\"X_train shape: {X_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}\")\n",
    "        \n",
    "        # Umformung der Daten für CNN-LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "        # Überprüfen der Formen der Daten nach Umformung\n",
    "        print(f\"Reshaped X_train shape: {X_train.shape}\")\n",
    "        print(f\"Reshaped X_val shape: {X_val.shape}\")\n",
    "        print(f\"Reshaped X_test shape: {X_test.shape}\")\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "        # Modellarchitektur definieren\n",
    "        model = Sequential()\n",
    "        # Hinzufügen von CNN-Schichten\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(SEQ_LENGTH, len(selected_features))))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        # Hinzufügen von LSTM-Schichten\n",
    "        model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Modell trainieren\n",
    "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val))\n",
    "\n",
    "        # Modell bewerten\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss}')\n",
    "        print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "        # MLflow-Logging\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        # Vorhersagen treffen und Wahrscheinlichkeiten in binäre Werte umwandeln\n",
    "        predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        print('Confusion Matrix')\n",
    "        print(cm)\n",
    "\n",
    "        # Classification Report\n",
    "        cr = classification_report(y_test, predictions)\n",
    "        print('Classification Report')\n",
    "        print(cr)\n",
    "\n",
    "        # Log confusion matrix and classification report\n",
    "        with open(\"confusion_matrix_lstm.txt\", \"w\") as f:\n",
    "            f.write(str(cm))\n",
    "        mlflow.log_artifact(\"confusion_matrix_lstm.txt\")\n",
    "\n",
    "        with open(\"classification_report_lstm.txt\", \"w\") as f:\n",
    "            f.write(cr)\n",
    "        mlflow.log_artifact(\"classification_report_lstm.txt\")\n",
    "\n",
    "        # Set a tag for the run\n",
    "        mlflow.set_tag(\"model\", \"CNN-LSTM\")\n",
    "\n",
    "# Extrahiere die Ergebnisse und plotte Learning Rate vs. Loss\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Bitcoin Price Movement Prediction CNN LSTM Learning Rate\")\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "learning_rates = []\n",
    "losses = []\n",
    "\n",
    "for run in runs:\n",
    "    learning_rate = run.data.params['learning_rate']\n",
    "    loss = run.data.metrics['loss']\n",
    "    learning_rates.append(float(learning_rate))\n",
    "    losses.append(float(loss))\n",
    "\n",
    "# Plot the Learning Rate vs Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(learning_rates, losses, marker='o', linestyle='-', color='b')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Rate vs Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter-Definition und Modelltraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen treffen\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Modell bewerten\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell bewerten\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# MLflow-Logging\n",
    "mlflow.log_metric(\"loss\", loss)\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.keras.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse visualisieren\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, predictions)\n",
    "print('Classification Report')\n",
    "print(cr)\n",
    "\n",
    "# Plot der Ergebnisse\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test, color='blue', label='Actual')\n",
    "plt.plot(predictions, color='red', label='Predicted')\n",
    "plt.title('Bitcoin Price Movement Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, predictions)\n",
    "print('Classification Report')\n",
    "print(cr)\n",
    "\n",
    "# Plot der Ergebnisse\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.scatter(range(len(y_test)), y_test, color='blue', label='Actual', marker='o')\n",
    "plt.scatter(range(len(predictions)), predictions, color='red', label='Predicted', marker='x')\n",
    "plt.title('Bitcoin Price Movement Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, where='post', label='Average precision score: AP={0:0.2f}'.format(average_precision))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(y_pred_prob, bins=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('Histogram of Predicted Probabilities')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimierungsmöglichkeiten für wenn Lifecycle Management Tool eingeführt ist:\n",
    "\n",
    "Wenn Sie die Preisbewegung (zum Beispiel die Richtung der Preisänderung oder die prozentuale Änderung) anstelle des tatsächlichen Preises vorhersagen und feststellen, dass die Leistung des Modells nicht zufriedenstellend ist, gibt es mehrere Ansätze, um die Vorhersagequalität zu verbessern. Hier sind einige Strategien, die Sie in Betracht ziehen können:\n",
    "\n",
    "\n",
    "### 2. **Modellarchitektur anpassen**\n",
    "- **Anzahl der LSTM-Einheiten ändern**: Erhöhen oder verringern Sie die Anzahl der Neuronen in den LSTM-Schichten, um zu sehen, ob dies die Modellleistung beeinflusst.\n",
    "- **Tiefe des Netzwerks**: Fügen Sie mehrere LSTM-Schichten hinzu, um ein tieferes Netzwerk zu erstellen, das möglicherweise komplexere Muster erfassen kann.\n",
    "- **Dropout hinzufügen**: Um Overfitting zu vermeiden, fügen Sie Dropout-Schichten hinzu, die helfen können, die Generalisierbarkeit des Modells zu verbessern.\n",
    "\n",
    "### 3. **Hyperparameter optimieren**\n",
    "- **Lernrate anpassen**: Experimentieren Sie mit unterschiedlichen Lernraten und anderen Optimierungsparametern.\n",
    "- **Batch-Größe und Epochenzahl**: Das Ändern der Batch-Größe und der Anzahl der Epochen kann erhebliche Auswirkungen auf das Trainingsergebnis haben.\n",
    "- **Regularisierung anwenden**: Experimentieren Sie mit verschiedenen Arten von Regularisierungen (L1, L2), um das Overfitting zu kontrollieren.\n",
    "\n",
    "### 4. **Verlustfunktion anpassen**\n",
    "- **Andere Verlustfunktionen ausprobieren**: Wenn Sie die Richtung der Preisbewegung vorhersagen, könnte eine binäre Kreuzentropie (wenn es sich um eine Klassifikationsaufgabe handelt) oder eine benutzerdefinierte Verlustfunktion, die speziell für Ihr Vorhersageziel entwickelt wurde, nützlich sein.\n",
    "\n",
    "### 5. **Trainingstechniken überprüfen**\n",
    "- **Frühzeitiges Beenden**: Verwenden Sie Early Stopping, um das Training zu beenden, wenn sich die Validierungsleistung nicht mehr verbessert.\n",
    "- **Daten-Shuffling und -Partitionierung**: Stellen Sie sicher, dass Ihre Trainings-, Validierungs- und Testdatensätze richtig partitioniert und während des Trainings effektiv gemischt werden.\n",
    "\n",
    "### 6. **Evaluation und Benchmarking**\n",
    "- **Cross-Validation verwenden**: Statt einer einfachen Train-Test-Split kann Cross-Validation eine robustere Evaluation der Modellleistung bieten.\n",
    "- **Leistungsmetriken**: Überprüfen Sie, ob Sie die richtigen Metriken für die Bewertung des Modells verwenden. Für Klassifikationsaufgaben sind Genauigkeit, F1-Score, ROC-AUC usw. relevant.\n",
    "\n",
    "Diese Ansätze bieten verschiedene Wege, die Modellleistung zu verbessern und sollten je nach spezifischem Szenario und den Ergebnissen der initialen Modellbewertungen angepasst werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualisierung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"C:\\WWI2021\\Semester 6\\Machine Learning Project\\LSTM_BTC\\data\\BTC-USD.csv\")\n",
    "\n",
    "\n",
    "data['Previous_Close'] = data['Close'].shift(1)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Zielvariablen für die Visualisierung erstellen\n",
    "data['Price_Change'] = data['Close'] - data['Previous_Close']\n",
    "data['Price_Movement'] = data['Price_Change'].apply(lambda x: 'Steigen' if x > 0 else 'Fallen')\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['Date'], data['Price_Movement'].apply(lambda x: 1 if x == 'Steigen' else -1), marker='o', linestyle='-', color='b')\n",
    "plt.yticks([1, -1], ['Steigen', 'Fallen'])\n",
    "plt.title('Bitcoin Preisbewegung')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Bewegung')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
