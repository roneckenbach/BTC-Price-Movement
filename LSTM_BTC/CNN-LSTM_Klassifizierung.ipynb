{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigentliche gute Vorhersage.\n",
    "Jetzt mehr backcandles ausprobieren, hyperparamter anapassen. inputs wo 150 ist. möglichkeit weitere indikatoren oder wie auch immer.\n",
    "\n",
    "PROBLEM: Warum das Modell einen Denkfehler hat: Das Modell lernt, dass der aktuelle closingprice nicht all zu weit vom nächsten closingpreis entfernt seien wird. Jeder vorhergesagte Wert der nah am Closingpreis des vorherigen Tages ist, sieht aus als sei er genau.\n",
    "Es sieht gut aus aber man kann erkennen, dass vorhersage nur 1 Tag verzögerter tatsächlicher Wert ist.\n",
    "Modell versucht Closing Preis des nächsten Tages vorherzusagen anhand vergangener Daten. Das wird für jeden Tag getestet und soll zukpünftige Werte vorherzusagen\n",
    "\n",
    "Neuer Ansatz. Target ist der Unterschied zwischen Close der aktuellen Kerze zur nächsten Close Kerze. Es wird nun statt dem Closepreis des nächsten Tages vorherzusagen, versucht um wie viel der preis hoch oder runter geht. Wo ist der Unterschied? Nächster candle Price vs Preisbewegung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Bibliotheken\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import ta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen des MLflow Tracking URI und Anlegen eines neuen Experiments\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Bitcoin Price Movement Prediction LSTM v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.\\venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\WWI2021\\Semester 6\\Machine Learning Project\\LSTM_BTC\\data\\BTC-USD.csv\")\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen der Korrelationsmatrix\n",
    "corr = data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='Blues', mask=mask, cbar_kws={'label': 'Korrelationskoeffizient'},\n",
    "            linewidths=0.5, linecolor='white')\n",
    "plt.title('Korrelationsmatrix der Features', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RSI'] = ta.momentum.RSIIndicator(data['Close']).rsi()\n",
    "data['EMA20'] = ta.trend.EMAIndicator(data['Close'], window=20).ema_indicator()\n",
    "data['EMA100'] = ta.trend.EMAIndicator(data['Close'], window=100).ema_indicator()\n",
    "data['EMA150'] = ta.trend.EMAIndicator(data['Close'], window=150).ema_indicator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Moving Average (SMA)\n",
    "data['SMA50'] = ta.trend.SMAIndicator(close=data['Close'], window=50).sma_indicator()\n",
    "# Momentum Indicator\n",
    "data['Momentum'] = ta.momentum.ROCIndicator(close=data['Close'], window=10).roc()\n",
    "# Rate of Change (ROC)\n",
    "data['ROC'] = ta.momentum.ROCIndicator(close=data['Close'], window=12).roc()\n",
    "# Bollinger Bands\n",
    "bollinger = ta.volatility.BollingerBands(close=data['Close'], window=20, window_dev=2)\n",
    "data['Bollinger_Middle'] = bollinger.bollinger_mavg()\n",
    "data['Bollinger_Upper'] = bollinger.bollinger_hband()\n",
    "data['Bollinger_Lower'] = bollinger.bollinger_lband()\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "macd = ta.trend.MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "data['MACD'] = macd.macd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen der Korrelationsmatrix\n",
    "corr = data[['Close', 'RSI', 'EMA20', 'EMA100', 'EMA150', 'SMA50', 'Momentum', 'ROC', 'Bollinger_Middle', 'Bollinger_Upper', 'Bollinger_Lower', 'MACD']].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='Blues', mask=mask, cbar_kws={'label': 'Korrelationskoeffizient'},\n",
    "            linewidths=0.5, linecolor='white')\n",
    "plt.title('Korrelationsmatrix der Features', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Auswahl für das Modell\n",
    "Aufgrund der hohen Korrelation und der Multikollinearität macht es Sinn, redundante Features zu eliminieren und nur repräsentative Features zu behalten. Hier ist eine mögliche Auswahl:\n",
    "\n",
    "EMA20 oder SMA50: Behalte nur eines dieser Features, da beide stark miteinander und mit dem Ziel korrelieren. Zum Beispiel: EMA20.\n",
    "Bollinger_Middle: Da es stark korreliert ist und repräsentativ für die Bollinger-Bänder ist, könnte man Bollinger_Middle anstelle von Upper und Lower behalten.\n",
    "MACD: Trotz der negativen Korrelation kann MACD hilfreich sein, da es eine andere Dimension der Preisbewegung darstellt.\n",
    "RSI: Obwohl die Korrelation gering ist, bietet RSI ein anderes Signal, das das Modell möglicherweise ergänzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Date','High', 'Low', 'Adj Close', 'Volume','Open', 'EMA100', 'EMA150', 'SMA50', 'Momentum', 'ROC', 'Bollinger_Upper', 'Bollinger_Lower'], axis=1, inplace=True)\n",
    "data['Previous_Close'] = data['Close'].shift(1)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zielvariablen für die Vorhersage erstellen\n",
    "data['Target'] = (data['Close'] <= data['Previous_Close']).astype(int)\n",
    "\n",
    "data_clean = data\n",
    "data_clean.dropna(inplace=True)\n",
    "data_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl und Skalierung der relevanten Features\n",
    "selected_features = ['Close', 'RSI', 'EMA20', 'Bollinger_Middle', 'MACD', 'Previous_Close']\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = sc.fit_transform(data[selected_features])\n",
    "\n",
    "def create_sequences(features, target, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        sequence = features[i:i + seq_length]\n",
    "        label = target[i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Hyperparameter-Definition\n",
    "learning_rates = [0.1, 0.05, 0.01, 0.001]\n",
    "epochs_list = [10, 30, 40, 50]\n",
    "seq_lengths = [30, 40, 50, 60]\n",
    "\n",
    "# Alle Kombinationen der Hyperparameter erzeugen\n",
    "combinations = list(itertools.product(learning_rates, epochs_list, seq_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, epochs, SEQ_LENGTH in combinations:\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": 32,\n",
    "            \"seq_length\": SEQ_LENGTH\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Daten vorbereiten basierend auf der aktuellen seq_length\n",
    "        X, y = create_sequences(scaled_features, data['Target'].values, SEQ_LENGTH)\n",
    "\n",
    "        # Datenaufteilung: 70% Training, 20% Validierung, 10% Test\n",
    "        train_size = int(0.7 * len(X))\n",
    "        val_size = int(0.2 * len(X))\n",
    "        test_size = len(X) - train_size - val_size\n",
    "\n",
    "        X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "        y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "        # Reshape für LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "        # Modellarchitektur definieren\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, activation='relu', input_shape=(SEQ_LENGTH, len(selected_features)), return_sequences=True))\n",
    "        model.add(LSTM(units=50, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Modell trainieren\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "        # Modell bewerten\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f'Test Loss: {loss}')\n",
    "        print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "        # MLflow-Logging\n",
    "        mlflow.log_metric(\"loss\", loss)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        # Vorhersagen treffen und Wahrscheinlichkeiten in binäre Werte umwandeln\n",
    "        predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        print('Confusion Matrix')\n",
    "        print(cm)\n",
    "\n",
    "        # Classification Report\n",
    "        cr = classification_report(y_test, predictions)\n",
    "        print('Classification Report')\n",
    "        print(cr)\n",
    "\n",
    "        # Log confusion matrix and classification report\n",
    "        with open(\"confusion_matrix_lstm.txt\", \"w\") as f:\n",
    "            f.write(str(cm))\n",
    "        mlflow.log_artifact(\"confusion_matrix_lstm.txt\")\n",
    "\n",
    "        with open(\"classification_report_lstm.txt\", \"w\") as f:\n",
    "            f.write(cr)\n",
    "        mlflow.log_artifact(\"classification_report_lstm.txt\")\n",
    "\n",
    "        # Set a tag for the run\n",
    "        mlflow.set_tag(\"model\", \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter-Definition und Modelltraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen treffen\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Modell bewerten\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell bewerten\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# MLflow-Logging\n",
    "mlflow.log_metric(\"loss\", loss)\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.keras.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse visualisieren\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, predictions)\n",
    "print('Classification Report')\n",
    "print(cr)\n",
    "\n",
    "# Plot der Ergebnisse\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test, color='blue', label='Actual')\n",
    "plt.plot(predictions, color='red', label='Predicted')\n",
    "plt.title('Bitcoin Price Movement Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print('Confusion Matrix')\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, predictions)\n",
    "print('Classification Report')\n",
    "print(cr)\n",
    "\n",
    "# Plot der Ergebnisse\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.scatter(range(len(y_test)), y_test, color='blue', label='Actual', marker='o')\n",
    "plt.scatter(range(len(predictions)), predictions, color='red', label='Predicted', marker='x')\n",
    "plt.title('Bitcoin Price Movement Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Class')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "average_precision = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, where='post', label='Average precision score: AP={0:0.2f}'.format(average_precision))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(y_pred_prob, bins=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('Histogram of Predicted Probabilities')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimierungsmöglichkeiten für wenn Lifecycle Management Tool eingeführt ist:\n",
    "\n",
    "Wenn Sie die Preisbewegung (zum Beispiel die Richtung der Preisänderung oder die prozentuale Änderung) anstelle des tatsächlichen Preises vorhersagen und feststellen, dass die Leistung des Modells nicht zufriedenstellend ist, gibt es mehrere Ansätze, um die Vorhersagequalität zu verbessern. Hier sind einige Strategien, die Sie in Betracht ziehen können:\n",
    "\n",
    "\n",
    "### 2. **Modellarchitektur anpassen**\n",
    "- **Anzahl der LSTM-Einheiten ändern**: Erhöhen oder verringern Sie die Anzahl der Neuronen in den LSTM-Schichten, um zu sehen, ob dies die Modellleistung beeinflusst.\n",
    "- **Tiefe des Netzwerks**: Fügen Sie mehrere LSTM-Schichten hinzu, um ein tieferes Netzwerk zu erstellen, das möglicherweise komplexere Muster erfassen kann.\n",
    "- **Dropout hinzufügen**: Um Overfitting zu vermeiden, fügen Sie Dropout-Schichten hinzu, die helfen können, die Generalisierbarkeit des Modells zu verbessern.\n",
    "\n",
    "### 3. **Hyperparameter optimieren**\n",
    "- **Lernrate anpassen**: Experimentieren Sie mit unterschiedlichen Lernraten und anderen Optimierungsparametern.\n",
    "- **Batch-Größe und Epochenzahl**: Das Ändern der Batch-Größe und der Anzahl der Epochen kann erhebliche Auswirkungen auf das Trainingsergebnis haben.\n",
    "- **Regularisierung anwenden**: Experimentieren Sie mit verschiedenen Arten von Regularisierungen (L1, L2), um das Overfitting zu kontrollieren.\n",
    "\n",
    "### 4. **Verlustfunktion anpassen**\n",
    "- **Andere Verlustfunktionen ausprobieren**: Wenn Sie die Richtung der Preisbewegung vorhersagen, könnte eine binäre Kreuzentropie (wenn es sich um eine Klassifikationsaufgabe handelt) oder eine benutzerdefinierte Verlustfunktion, die speziell für Ihr Vorhersageziel entwickelt wurde, nützlich sein.\n",
    "\n",
    "### 5. **Trainingstechniken überprüfen**\n",
    "- **Frühzeitiges Beenden**: Verwenden Sie Early Stopping, um das Training zu beenden, wenn sich die Validierungsleistung nicht mehr verbessert.\n",
    "- **Daten-Shuffling und -Partitionierung**: Stellen Sie sicher, dass Ihre Trainings-, Validierungs- und Testdatensätze richtig partitioniert und während des Trainings effektiv gemischt werden.\n",
    "\n",
    "### 6. **Evaluation und Benchmarking**\n",
    "- **Cross-Validation verwenden**: Statt einer einfachen Train-Test-Split kann Cross-Validation eine robustere Evaluation der Modellleistung bieten.\n",
    "- **Leistungsmetriken**: Überprüfen Sie, ob Sie die richtigen Metriken für die Bewertung des Modells verwenden. Für Klassifikationsaufgaben sind Genauigkeit, F1-Score, ROC-AUC usw. relevant.\n",
    "\n",
    "Diese Ansätze bieten verschiedene Wege, die Modellleistung zu verbessern und sollten je nach spezifischem Szenario und den Ergebnissen der initialen Modellbewertungen angepasst werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
